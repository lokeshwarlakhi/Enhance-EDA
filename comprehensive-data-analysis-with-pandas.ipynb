{"cells":[{"cell_type":"markdown","metadata":{},"source":["<a class=\"anchor\" id=\"0\"></a>\n","# **Comprehensive Data Analysis with Pandas**\n","\n","\n","Hello friends,\n","\n","\n","Pandas is an open source library for data analysis in Python. In this project, I explore pandas and important data analysis tools of pandas. \n","\n","\n","So, let's get started."]},{"cell_type":"markdown","metadata":{},"source":["**I hope you find this kernel useful and your <font color=\"red\"><b>UPVOTES</b></font> would be highly appreciated**."]},{"cell_type":"markdown","metadata":{},"source":["## Table of contents <a class=\"anchor\" id=\"0.1\"></a>\n","\n","\n","1.  [Introduction to Pandas](#1)\n","\n","1.\t[Key features of Pandas](#2)\n","\n","1.\t[Advantages of Pandas](#3)\n","\n","1.\t[Importing Pandas](#4)\n","\n","1.\t[Data structures in Pandas](#5)\n","\n","1.\t[Pandas series](#6)\n","\n","1.\t[Pandas dataframe](#7)\n","\n","1.\t[Pandas panel](#8)\n","\n","1.\t[Data import with pandas](#9)\n","\n","1.\t[Exploratory data analysis](#10)\n","\n","1.\t[Handle missing values with pandas](#11)\n","\n","1.\t[Indexing and slicing in pandas](#12)\n","\n","1.\t[Indexing and reindexing in pandas](#13)\n","\n","1.\t[MultiIndex or advanced indexing](#14)\n","\n","1.\t[Sorting in pandas](#15)\n","\n","1.\t[Categorical data in pandas](#16)\n","\n","1.\t[Basic functionality in pandas](#17)\n","\n","1.\t[Descriptive statistics in pandas](#18)\n","\n","1.\t[Statistical functions in pandas](#19)\n","\n","1.\t[Window functions in pandas](#20)\n","\n","1.\t[Aggregations in pandas](#21)\n","\n","1.\t[Iteration in pandas](#22)\n","\n","1.\t[Function application in pandas](#23)\n","\n","1.\t[Pandas GroupBy operations](#24)\n","\n","1.\t[Pandas merging and joining](#25)\n","\n","1.\t[Pandas concatenation operation](#26)\n","\n","1.\t[Reshaping by melt and pivot](#27)\n","\n","1.\t[Reshaping by stacking and unstacking](#28)\n","\n","1.\t[Options and customization with pandas](#29)\n","\n","1.\t[Summary and conclusion](#30)\n"]},{"cell_type":"markdown","metadata":{},"source":["# 1. Introduction to Pandas <a class=\"anchor\" id=\"1\"></a>\n","\n","\n","[Back to Table of Contents](#0.1)\n","\n","\n","\n","- Today, Python is considered as the most popular programming language for doing data science work.  The reason behind this popularity is that Python provides great packages for doing data analysis and visualization work. \n","\n","\n","\n","- **Pandas** is one of those packages that makes analysing data much easier. Pandas is an open source library for data analysis in Python. It was developed by Wes McKinney in 2008. Over the years, it has become the standard library for data analysis using Python.\n","\n","\n","- According to the Wikipedia page on Pandas,\n","\n","\n","\n","  - **\"Pandas offers data structures and operations for manipulating numerical tables and time series. It is free software released under the three-clause BSD license. The name is derived from the term 'panel data', an econometrics term for data sets that include observations over multiple time periods for the same individuals.\"**\n","\n","\n","\n","- In this project, I explore Pandas and various data analysis tools provided by Pandas.\n"]},{"cell_type":"markdown","metadata":{},"source":["# 2. Key features of Pandas <a class=\"anchor\" id=\"2\"></a>\n","\n","\n","[Back to Table of Contents](#0.1)\n","\n","\n","Some key features of Pandas are as follows:-\n","\n","\n","1.\tIt provides tools for reading and writing data from a wide variety of sources such as CSV files, excel files, \n","    databases such as SQL, JSON files.    \n","    \n","2.\tIt provides different data structures like series, dataframe and panel for data manipulation and indexing.\n","\n","3.\tIt can handle wide variety of data sets in different formats – time series, heterogeneous data, tabular and matrix data.\n","\n","4.\tIt can perform variety of operations on datasets. It includes subsetting, slicing, filtering, merging, joining, groupby, reordering and reshaping operations.\n","    \n","5.\tIt can deal with missing data by either deleting them or filling them with zeros or a suitable test statistic.\n","\n","6.\tIt can be used for parsing and conversion of data.\n","\n","7.\tIt provides data filtration techniques.\n","\n","8.\tIt provides time series functionality – date range generation, frequency conversion, moving window statistics, \n","    data shifting and lagging.    \n"," \n","9.\tIt integrates well with other Python libraries such as Scikit-learn, statsmodels and SciPy.\n","\n","10.\tIt delivers fast performance. Also, it can be speeded up even more by making use of Cython (C extensions to Python).\n"]},{"cell_type":"markdown","metadata":{},"source":["# 3. Advantages of Pandas <a class=\"anchor\" id=\"3\"></a>\n","\n","\n","[Back to Table of Contents](#0.1)\n","\n","\n","Pandas is a core component of the Python data analysis toolkit. Pandas provides data structure and operations facilities, \n","which is particularly useful for data analysis. There are various advantages of using Pandas for data analysis. \n","\n","These advantages are as follows:-\n","\n","### **Data representation** \n","\n","It represents data in a form that is very much suited for data analysis through its Dataframe and Series data structures.                              \n","                           \n","### **Data subsetting and filtering** \n","\n","It provides for easy subsetting and filtering of data. It provides procedures that are suited for data analysis.                                    \n","                                 \n","### **Concise and clear code** \n","\n","It provides functionality to write clear and concise code. It allows us to focus on the task at hand, rather than have to write tedious code.\n"]},{"cell_type":"markdown","metadata":{},"source":["# 4. Importing Pandas <a class=\"anchor\" id=\"4\"></a>\n","\n","[Back to Table of Contents](#0.1)\n","\n","\n","In order to use Pandas in our work, we need to import the Pandas library first. We can import the Pandas library with the following command:-\n","\n","\n","`import pandas`\n","\n","\n","Usually, we import the Pandas library by appending the alias `as pd`.  It makes things easier because now instead of writing `pandas.command` we need to write `pd.command`. So, we will import pandas with the following command:-\n","\n","\n","`import pandas as pd`\n","\n","\n","Also, I will import Numpy as well, because it is very useful library for scientific computing with Python. I will import Numpy with the following command:-\n","\n","\n","`import numpy as np`\n"]},{"cell_type":"code","execution_count":1,"metadata":{"trusted":true},"outputs":[],"source":["# import pandas and numpy\n","\n","import pandas as pd\n","\n","import numpy as np"]},{"cell_type":"markdown","metadata":{},"source":["# 5. Data structures in Pandas <a class=\"anchor\" id=\"5\"></a>\n","\n","[Back to Table of Contents](#0.1)\n","\n","\n","Pandas provide easy to use data structures. \n","\n","\n","There are three main data structures in Pandas. They are:-\n","\n","\n","-\tSeries\n","\n","-\tDataframe\n","\n","-\tPanel\n","\n","\n","These data structures are built on top of Numpy array, which means they are fast. I have described these data structures in the following sections.\n"]},{"cell_type":"markdown","metadata":{},"source":["# 6. Pandas Series <a class=\"anchor\" id=\"6\"></a>\n","\n","\n","[Back to Table of Contents](#0.1)\n","\n","\n","\n","A Pandas Series is a one-dimensional array like structure with homogeneous data.  \n","\n","\n","The data can be of any type (integer, string, float, etc.). The axis labels are collectively called index. \n","\n","\n","For example, the following series is a collection of integers 10, 20, 30, 40, 50, 60, 70, 80, 90, 100.\n","\n","\n","\n","\n","\n","### Key Points of Pandas Series\n","\n","\n","-\tHomogeneous data\n","\n","-\tSize of series immutable\n","\n","-\tValues of data mutable\n","\n","\n","\n","\n","\n","### Series Constructor\n","\n","\n","\n","\n","A Pandas Series can be created using the following constructor −\n","\n","\n","`pandas. Series (data, index, dtype, copy)`\n","\n","\n","The parameters of the constructor are as follows –\n","\n","\n","-\t**data** - data takes various forms like ndarray, list, dictionary, constants, etc.\n","\n","\n","-\t**index**- index values must be unique, hashable and have the same length as data. The default index is RangeIndex (0, 1, 2,\n","               …, n) if no index is passed.\n","     \n","     \n","-\t**dtype** - dtype is for data type. If none, data type will be inferred.\n","\n","\n","-\t**copy** - Copy input data. Default value is False.\n"]},{"cell_type":"markdown","metadata":{},"source":["# 7. Pandas DataFrame <a class=\"anchor\" id=\"7\"></a>\n","\n","\n","[Back to Table of Contents](#0.1)\n","\n","\n","\n","A Dataframe is a two-dimensional data structure. So, data is aligned in a tabular fashion in rows and columns. \n","Its column types can be heterogeneous:  - that is, of varying types. It is similar to structured arrays in NumPy \n","with mutability added.\n","\n","\n","\n","### Properties of Dataframe are as follows:-\n","\n","\n","-\tThe dataframe is conceptually analogous to a table or spreadsheet of data. \n","\n","\n","-\tIts columns are of different types – float64, int, bool, and so on.\n","\n","\n","-\tA Dataframe column is a Series structure.\n","\n","\n","-\tIts size is mutable – columns can be inserted and deleted.\n","\n","\n","-\tIt has labelled axes (rows and columns).\n","\n","\n","-\tIt can be thought of as a dictionary of Series structures where both the rows and columns are indexed, \n","    denoted as `index` in the case of rows and `columns` in the case of columns.\n","    \n","    \n","-\tIt can perform arithmetic operations on rows and columns.\n","\n","\n","\n","### Dataframe Constructor\n","\n","\n","\n","Dataframe is the most commonly used data structure in pandas. \n","\n","\n","A pandas Dataframe can be created using the following constructor-\n","\n","\n","`pandas.DataFrame(data, index, columns, dtype, copy)`\n","\n","\n","The constructor accepts many different types of arguments: \n","\n","\n","\tDictionary of 1D ndarrays, lists, dictionaries, or Series structures \n","    \n","\t2D NumPy array\n","    \n","\tStructured or record ndarray\n","    \n","\tSeries structures\n","    \n","\tAnother DataFrame structure \n","\n","\n","\n","The parameters description of the constructor is as follows –\n","\n","\n","-**data** - data takes various forms like ndarray, series, map, lists, dict, constants and also another DataFrame.\n","\n","\n","-**index**- Index or array-like \n","\n","\n","            Index to use for resulting frame. Will default to RangeIndex if no indexing information part of \n","            input data and no index provided\n","            \n","\n","-**columns**- Index or array-like\n","\n","\n","              Column labels to use for resulting frame. Will default to RangeIndex (0, 1, 2, …, n) if no column labels are  \n","              provided.\n","              \n","              \n","-**dtype** - data type of each column\n","\n","\n","\n","-**copy** - boolean, default False\n","\n","\n","            Copy data from inputs. Only affects DataFrame / 2d ndarray input\n","\n","\n","\n","\n","### Dataframe Creation\n","\n","\n","A pandas Dataframe can be created using various inputs like −\n","\n","\n","•\tLists\n","\n","•\tdict\n","\n","•\tSeries\n","\n","•\tNumpy ndarrays\n","\n","•\tAnother Dataframe\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["# 8. Pandas Panel <a class=\"anchor\" id=\"8\"></a>\n","\n","\n","[Back to Table of Contents](#0.1)\n","\n","\n","\n","A panel is a 3D container of data. \n","\n","\n","The term Panel data is derived from **econometrics** and is partially responsible for the name pandas − pan(el)-da(ta)-s.\n","\n","\n","The names for the 3 axes are intended to give some semantic meaning to describing operations involving panel data. \n","\n","\n","They are −\n","\n","\n","`items − axis 0`, each item corresponds to a DataFrame contained inside.\n","\n","\n","`major_axis − axis 1`, it is the index (rows) of each of the DataFrames.\n","\n","\n","`minor_axis − axis 2`, it is the columns of each of the DataFrames."]},{"cell_type":"markdown","metadata":{},"source":["# 9. Data import with Pandas <a class=\"anchor\" id=\"9\"></a>\n","\n","\n","[Back to Table of Contents](#0.1)\n","\n","\n","Pandas input output API provides several functions that can be used to import and export various file formats. \n","\n","\n","Below is the list of file formats and the corresponding functions to import these file formats.\n","\n","\n","- Flat files - read_csv(), to_csv()\n","\n","- Excel files - read_excel(), ExcelWriter(), to_excel()\n","\n","- JSON files - read_json(), to_json()\n","\n","- HTML tables - read_html(), to_html()\n","\n","- SAS files - read_sas()\n","\n","- SQL files - read_sql(), read_sql_query(), read_sql_table(), to_sql()\n","\n","- STATA files - read_stata(), to_stata()\n","\n","- pickle object - read_pickle(), to_pickle()\n","\n","- HDF5 files - read_hdf(), to_hdf()"]},{"cell_type":"markdown","metadata":{},"source":["In this project, I work with the **BlackFriday dataset** which is a comma-separated values (CSV) file type. In a CSV file type, the data is stored as a comma-separated values where each row is separated by a new line, and each column by a comma (,). Also, in some sections, I create my own dataset to discuss the respective functionality.\n","\n","\n","So, I use the **read_csv()** function to import the file as follows:-"]},{"cell_type":"code","execution_count":2,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/input/black-friday/train.csv\n","/kaggle/input/black-friday/test.csv\n"]}],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load in \n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the \"../input/\" directory.\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# Any results you write to the current directory are saved as output.\n"]},{"cell_type":"code","execution_count":3,"metadata":{"trusted":true},"outputs":[],"source":["data = '/kaggle/input/black-friday/train.csv'\n","\n","df = pd.read_csv(data)"]},{"cell_type":"markdown","metadata":{},"source":["# 10. Exploratory Data Analysis <a class=\"anchor\" id=\"10\"></a>\n","\n","\n","[Back to Table of Contents](#0.1)\n","\n","\n","The next step is to conduct exploratory data analysis. "]},{"cell_type":"markdown","metadata":{},"source":["### check the type of df\n","\n","\n","I have imported the dataset. The next step is to check its type. We can check its type with the following command:-"]},{"cell_type":"code","execution_count":4,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["pandas.core.frame.DataFrame"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["type(df)"]},{"cell_type":"markdown","metadata":{},"source":["We can see that the `df` is the pandas dataframe."]},{"cell_type":"markdown","metadata":{},"source":["### check shape of dataframe\n","\n","\n","The next step is to check the shape of the dataframe. We can check the shape of the dataframe as follows:-"]},{"cell_type":"code","execution_count":5,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["(550068, 12)"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["df.shape"]},{"cell_type":"markdown","metadata":{},"source":["There are 550068 rows and 12 columns in the train dataset."]},{"cell_type":"markdown","metadata":{},"source":["### view the first five rows of the dataframe\n","\n","\n","We can view the first 5 rows of the dataframe with **head()** method as follows:-"]},{"cell_type":"code","execution_count":6,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>User_ID</th>\n","      <th>Product_ID</th>\n","      <th>Gender</th>\n","      <th>Age</th>\n","      <th>Occupation</th>\n","      <th>City_Category</th>\n","      <th>Stay_In_Current_City_Years</th>\n","      <th>Marital_Status</th>\n","      <th>Product_Category_1</th>\n","      <th>Product_Category_2</th>\n","      <th>Product_Category_3</th>\n","      <th>Purchase</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1000001</td>\n","      <td>P00069042</td>\n","      <td>F</td>\n","      <td>0-17</td>\n","      <td>10</td>\n","      <td>A</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>8370</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1000001</td>\n","      <td>P00248942</td>\n","      <td>F</td>\n","      <td>0-17</td>\n","      <td>10</td>\n","      <td>A</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>6.0</td>\n","      <td>14.0</td>\n","      <td>15200</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1000001</td>\n","      <td>P00087842</td>\n","      <td>F</td>\n","      <td>0-17</td>\n","      <td>10</td>\n","      <td>A</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>12</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>1422</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1000001</td>\n","      <td>P00085442</td>\n","      <td>F</td>\n","      <td>0-17</td>\n","      <td>10</td>\n","      <td>A</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>12</td>\n","      <td>14.0</td>\n","      <td>NaN</td>\n","      <td>1057</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1000002</td>\n","      <td>P00285442</td>\n","      <td>M</td>\n","      <td>55+</td>\n","      <td>16</td>\n","      <td>C</td>\n","      <td>4+</td>\n","      <td>0</td>\n","      <td>8</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>7969</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   User_ID Product_ID Gender   Age  Occupation City_Category  \\\n","0  1000001  P00069042      F  0-17          10             A   \n","1  1000001  P00248942      F  0-17          10             A   \n","2  1000001  P00087842      F  0-17          10             A   \n","3  1000001  P00085442      F  0-17          10             A   \n","4  1000002  P00285442      M   55+          16             C   \n","\n","  Stay_In_Current_City_Years  Marital_Status  Product_Category_1  \\\n","0                          2               0                   3   \n","1                          2               0                   1   \n","2                          2               0                  12   \n","3                          2               0                  12   \n","4                         4+               0                   8   \n","\n","   Product_Category_2  Product_Category_3  Purchase  \n","0                 NaN                 NaN      8370  \n","1                 6.0                14.0     15200  \n","2                 NaN                 NaN      1422  \n","3                14.0                 NaN      1057  \n","4                 NaN                 NaN      7969  "]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["df.head()"]},{"cell_type":"markdown","metadata":{},"source":["### view concise summary of dataframe\n","\n","We can view the concise summary of dataframe with **info()** method as follows:-"]},{"cell_type":"code","execution_count":7,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 550068 entries, 0 to 550067\n","Data columns (total 12 columns):\n","User_ID                       550068 non-null int64\n","Product_ID                    550068 non-null object\n","Gender                        550068 non-null object\n","Age                           550068 non-null object\n","Occupation                    550068 non-null int64\n","City_Category                 550068 non-null object\n","Stay_In_Current_City_Years    550068 non-null object\n","Marital_Status                550068 non-null int64\n","Product_Category_1            550068 non-null int64\n","Product_Category_2            376430 non-null float64\n","Product_Category_3            166821 non-null float64\n","Purchase                      550068 non-null int64\n","dtypes: float64(2), int64(5), object(5)\n","memory usage: 50.4+ MB\n"]}],"source":["df.info()"]},{"cell_type":"markdown","metadata":{},"source":["# 11. Handle missing values with pandas <a class=\"anchor\" id=\"11\"></a>\n","\n","\n","[Back to Table of Contents](#0.1)\n","\n","\n","We can check the total number of missing values in each column in the dataset with the following command:-"]},{"cell_type":"code","execution_count":8,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["User_ID                            0\n","Product_ID                         0\n","Gender                             0\n","Age                                0\n","Occupation                         0\n","City_Category                      0\n","Stay_In_Current_City_Years         0\n","Marital_Status                     0\n","Product_Category_1                 0\n","Product_Category_2            173638\n","Product_Category_3            383247\n","Purchase                           0\n","dtype: int64"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["df.isnull().sum()"]},{"cell_type":"markdown","metadata":{},"source":["We can see that there are 166986 missing values in `Product_Category_2` and 373299 columns in `Product_Category_3` columns."]},{"cell_type":"markdown","metadata":{},"source":["###  isna() and notna() functions to detect 'NA' values\n","\n","\n","Pandas provides `isna()` and `notna()` functions to detect 'NA' values. \n","\n","These are also methods on Series and DataFrame objects.\n","\n","Examples of isna() and notna() commands.\n","\n","\n","\n","detect ‘NA’ values in the dataframe\t\n","\n","`df.isna().sum()`\n","\n","\n","\n","detect ‘NA’ values in a particular column in the dataframe\n","\n","\n","`pd.isna(df[‘col_name’])`\n","\n","\n","`df[‘col_name’].notna()`\n"]},{"cell_type":"code","execution_count":9,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["User_ID                            0\n","Product_ID                         0\n","Gender                             0\n","Age                                0\n","Occupation                         0\n","City_Category                      0\n","Stay_In_Current_City_Years         0\n","Marital_Status                     0\n","Product_Category_1                 0\n","Product_Category_2            173638\n","Product_Category_3            383247\n","Purchase                           0\n","dtype: int64"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["df.isna().sum()"]},{"cell_type":"markdown","metadata":{},"source":["We can see that all the missing values are encoded as `NA` values. If the missing values are encoded in different ways we should encode them first."]},{"cell_type":"markdown","metadata":{},"source":["### Encode missing numerical values\n","\n","\n","Missing values are encoded in different ways. They can appear as `NaN`, `NA`, `?`, `zeros`, `xx`, `-1` or a blank space `“ ”`. \n","We can use various pandas methods to deal with missing values. \n","\n","But, pandas always recognize missing values as `NaN`.  So, it is essential that we should first convert all the `?`, `zeros`, `xx`, `-1` or `“ ”` to `NaN`. If the missing values isn’t identified as `NaN`, then we have to first convert or replace \n","such `non NaN` entry with a `NaN`.\n","\n","\n","\n","### Convert '?' to ‘NaN’\n","\n","`df[df == '?'] = np.nan`\n"]},{"cell_type":"markdown","metadata":{},"source":["### Handle missing numerical values\n","\n","There are several methods to handle missing values. Each method has its own advantages and disadvantages. The choice of the method is subjective and depends on the nature of data and the missing values. In this section, I have listed the most commonly used methods to deal with missing values. They are as follows:-\n","\n","\n","- Drop missing values with dropna() method\n","\n","- Fill missing values with zeros\n","\n","- Fill missing values with a test statistic\n","\n","- Fill missing values backward or forward\n","\n","\n","\n","In this section, I have fill the missing values with forward or backward filling.\n","\n","\n","The **pad or fill** option fill values forward, while **bfill or backfill** option fill values backward. \n","\n","\n","The following code helps us to achieve this task:-"]},{"cell_type":"code","execution_count":10,"metadata":{"trusted":true},"outputs":[],"source":["df = df.fillna(method = 'pad')"]},{"cell_type":"markdown","metadata":{},"source":["Again, we should check whether missing values are removed or not."]},{"cell_type":"code","execution_count":11,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["User_ID                       0\n","Product_ID                    0\n","Gender                        0\n","Age                           0\n","Occupation                    0\n","City_Category                 0\n","Stay_In_Current_City_Years    0\n","Marital_Status                0\n","Product_Category_1            0\n","Product_Category_2            1\n","Product_Category_3            1\n","Purchase                      0\n","dtype: int64"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["df.isnull().sum()"]},{"cell_type":"markdown","metadata":{},"source":["We can see that the `Product_Category_2` and `Product_Category_3` have 1 missing value. We can use the **head()** to check this."]},{"cell_type":"code","execution_count":12,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Product_Category_2</th>\n","      <th>Product_Category_3</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>6.0</td>\n","      <td>14.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>6.0</td>\n","      <td>14.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>14.0</td>\n","      <td>14.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>14.0</td>\n","      <td>14.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Product_Category_2  Product_Category_3\n","0                 NaN                 NaN\n","1                 6.0                14.0\n","2                 6.0                14.0\n","3                14.0                14.0\n","4                14.0                14.0"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["df[['Product_Category_2', 'Product_Category_3']].head()"]},{"cell_type":"markdown","metadata":{},"source":["We can see that the first element of each column are NaN. So, in this case **pad** or **fill** option does not work. Here, we\n","should use **bfill** or **backfill** options as follows:-"]},{"cell_type":"code","execution_count":13,"metadata":{"trusted":true},"outputs":[],"source":["df = df.fillna(method = 'backfill')"]},{"cell_type":"markdown","metadata":{},"source":["Again, we should check whether missing values are filled or not."]},{"cell_type":"code","execution_count":14,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["User_ID                       0\n","Product_ID                    0\n","Gender                        0\n","Age                           0\n","Occupation                    0\n","City_Category                 0\n","Stay_In_Current_City_Years    0\n","Marital_Status                0\n","Product_Category_1            0\n","Product_Category_2            0\n","Product_Category_3            0\n","Purchase                      0\n","dtype: int64"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["df.isnull().sum()"]},{"cell_type":"markdown","metadata":{},"source":["### Check with ASSERT statement\n","\n","\n","Finally, we should check for missing values programmatically. If we drop or fill missing values, we expect no missing values. \n","We can write an assert statement to verify this. So, we can use an assert statement to programmatically check that no missing or unexpected '0' value is present. This gives confidence that our code is running properly.\n","\n","\n","Assert statement will return nothing if the value being tested is true and will throw an AssertionError if the value is false.\n","\n","\n","Asserts\n","\n","\n","•\tassert 1 == 1   (return Nothing if the value is True)\n","\n","\n","•\tassert 1 == 2   (return AssertionError if the value is False)\n"]},{"cell_type":"code","execution_count":15,"metadata":{"trusted":true},"outputs":[],"source":["#assert that there are no missing values in the dataframe\n","\n","assert pd.notnull(df).all().all()\n"]},{"cell_type":"markdown","metadata":{},"source":["The above command does not throw any AssertionError. So, it is confirmed that there are no missing values in the dataframe."]},{"cell_type":"markdown","metadata":{},"source":["# 12. Indexing and slicing in pandas <a class=\"anchor\" id=\"12\"></a>\n","\n","\n","[Back to Table of Contents](#0.1)\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["In this section, I will discuss how to slice and dice the data and get the subset of pandas dataframe.\n","\n","\n","Pandas provides three types of Multi-axes indexing. Those three types are mentioned in the following table:-\n","\n","\n","- 1. **.loc** - Label based\n","\n","\n","- 2. **.iloc** - Integer based\n","\n","\n","- 3. **.ix**  - Both Label and Integer based\n","\n","\n","Starting with pandas 0.20.0, the .ix indexer is deprecated, in favor of the more strict .iloc and .loc indexers. So, I will not discuss it here and limit the discussion to .loc and .iloc indexers."]},{"cell_type":"markdown","metadata":{},"source":["### Label based indexing using .loc indexer\n","\n","\n","Pandas provide **.loc indexer** to have purely label based indexing. When slicing, the start bound is also included. \n","Integers are valid labels, but they refer to the label and not the position.\n","\n","\n",".loc indexer has multiple access methods like −\n","\n","\n","- A single scalar label\n","\n","- A list of labels\n","\n","- A slice object\n","\n","- A Boolean array\n","\n","\n","**Syntax**-\n","\n","\n",".loc takes two single/list/range operator separated by ','. \n","\n","\n","The first one indicates the row and the second one indicates columns.\n","\n","\n","Below are the examples of selecting data using .loc indexer:-"]},{"cell_type":"code","execution_count":16,"metadata":{"trusted":true},"outputs":[],"source":["# make a copy of dataframe\n","df1 = df.copy()"]},{"cell_type":"code","execution_count":17,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["User_ID                         1000001\n","Product_ID                    P00069042\n","Gender                                F\n","Age                                0-17\n","Occupation                           10\n","City_Category                         A\n","Stay_In_Current_City_Years            2\n","Marital_Status                        0\n","Product_Category_1                    3\n","Product_Category_2                    6\n","Product_Category_3                   14\n","Purchase                           8370\n","Name: 0, dtype: object"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["# select first row of dataframe\n","\n","df1.loc[0]"]},{"cell_type":"code","execution_count":18,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["0     8370\n","1    15200\n","2     1422\n","3     1057\n","4     7969\n","Name: Purchase, dtype: int64"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["#select first five rows for a specific column\n","\n","df1.loc[:,'Purchase'].head()"]},{"cell_type":"markdown","metadata":{},"source":["Similar examples of selecting data using .loc indexer are as follows:-\n","\n","\n","Select all rows for multiple columns, say list[]\n","\n","`df1.loc[:,['Age','Occupation']]`\n","\n","\n","\n","Select first five rows for multiple columns, say list[]\n","\n","`df1.loc[[0, 1, 2, 3, 4],['Age','Occupation']]`\n","\n","\n","\n","Select range of rows for all columns\n","\n","`df1.loc[0:4]`\n","\n","\n","\n","The above functionality can also be given by\n","\n","`df1.head()`"]},{"cell_type":"markdown","metadata":{},"source":["### Integer position based indexing using .iloc indexer\n","\n","\n","Pandas provides **.iloc indexer** for integer position based indexing.\n","\n","\n",".iloc is primarily integer position based (from 0 to length-1 of the axis), but may also be used with a boolean array. \n",".iloc will raise IndexError if a requested indexer is out-of-bounds, except slice indexers which allow out-of-bounds indexing.  Allowed inputs of .iloc indexer are:-\n","\n","\n","- An integer e.g. 5.\n","\n","\n","- A list or array of integers [4, 3, 0].\n","\n","\n","- A slice object with ints 1:7.\n","\n","\n","- A boolean array."]},{"cell_type":"markdown","metadata":{},"source":["### Rows selection using .iloc indexer\n","\n","\n","Below are the examples of row selection using .iloc indexer\n","\n","\n","#### select first row of dataframe\n","\n","\n","df1.iloc[0]\n","\n","\n","\n","#### select second row of dataframe\n","\n","\n","df1.iloc[1]\n","\n","\n","\n","#### select last row of dataframe\n","\n","\n","df1.iloc[-1]\n","\n","\n","\n","#### select second last row of dataframe\n","\n","\n","df1.iloc[-2]"]},{"cell_type":"code","execution_count":19,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["User_ID                         1000001\n","Product_ID                    P00069042\n","Gender                                F\n","Age                                0-17\n","Occupation                           10\n","City_Category                         A\n","Stay_In_Current_City_Years            2\n","Marital_Status                        0\n","Product_Category_1                    3\n","Product_Category_2                    6\n","Product_Category_3                   14\n","Purchase                           8370\n","Name: 0, dtype: object"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["#select first row of dataframe\n","\n","df1.iloc[0]"]},{"cell_type":"code","execution_count":20,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["User_ID                         1006039\n","Product_ID                    P00371644\n","Gender                                F\n","Age                               46-50\n","Occupation                            0\n","City_Category                         B\n","Stay_In_Current_City_Years           4+\n","Marital_Status                        1\n","Product_Category_1                   20\n","Product_Category_2                    2\n","Product_Category_3                   11\n","Purchase                            490\n","Name: 550067, dtype: object"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["#select last row of dataframe\n","\n","df1.iloc[-1]"]},{"cell_type":"markdown","metadata":{},"source":["### Columns selection using .iloc indexer\n","\n","\n","#### select first column of dataframe\n","\n","`df1.iloc[:,0]`\n","\n","\n","\n","#### select second column of dataframe\n","\n","`df1.iloc[:,1]`\n","\n","\n","\n","#### select last column of dataframe\n","\n","`df1.iloc[:,-1]`\n","\n","\n","\n","#### select second last column of dataframe\n","\n","`df1.iloc[:,-2]`"]},{"cell_type":"markdown","metadata":{},"source":["### Multiple rows and columns selection using .iloc indexer\n","\n","\n","\n","#### select first five rows of dataframe\n","\n","`df1.iloc[0:5]`\n","\n","\n","\n","#### select first five columns of data frame with all rows\n","\n","`df1.loc[:, 0:5]`\n","\n","\n","\n","\n","#### select 1st, 5th and 10th rows with 1st, 4th and 7th columns\n","\n","`df1.iloc[[0,4,9]], [0,3,6]]`\n","\n","\n","\n","\n","#### select first 5 rows and 5th, 6th, 7th columns of data frame\n","\n","`df1.iloc[0:5, 5:8]`"]},{"cell_type":"markdown","metadata":{},"source":["### Indexing first occurrence of maximum or minimum values with idxmax() and idxmin()\n","\n","\n","Pandas provide two functions **idxmax()** and **idxmin()** that return index of first occurrence of maximum or minimum values over requested axis. NA/null values are excluded from the output."]},{"cell_type":"code","execution_count":21,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["87440"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["# get index of first occurence of maximum Purchase value \n","\n","df1['Purchase'].idxmax()"]},{"cell_type":"code","execution_count":22,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["User_ID                         1001474\n","Product_ID                    P00052842\n","Gender                                M\n","Age                               26-35\n","Occupation                            4\n","City_Category                         A\n","Stay_In_Current_City_Years            2\n","Marital_Status                        1\n","Product_Category_1                   10\n","Product_Category_2                   15\n","Product_Category_3                    8\n","Purchase                          23961\n","Name: 87440, dtype: object"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["# get the row with the maximum Purchase value \n","\n","df1.loc[df1['Purchase'].idxmax()]"]},{"cell_type":"markdown","metadata":{},"source":["### Indexing a single value with at() and iat()\n","\n","\n","Pandas provides **at()** and **iat()** functions to access a single value for a row and column pair by label or by integer position."]},{"cell_type":"code","execution_count":23,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["15200"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["# get value at 1st row and Purchase column pair\n","\n","df1.at[1, 'Purchase']"]},{"cell_type":"code","execution_count":24,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["15200"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["# get value at 1st row and 11th column pair\n","\n","df1.iat[1, 11]"]},{"cell_type":"markdown","metadata":{},"source":["### Boolean indexing in pandas\n","\n","\n","\n","**Boolean indexing** is the use of boolean vectors to filter and select the data. The operators for boolean indexing are -\n","\n","\n","- 1. | for or, \n","\n","\n","- 2. & for and,\n","\n","\n","- 3. ~ for not. \n","\n","\n","These must be grouped by using parentheses. Using a boolean vector to index a Series works exactly as in a NumPy ndarray.\n","\n","\n","Conditional selections with boolean arrays using **df.loc[selection]** is the most common method to use with Pandas DataFrames. With boolean indexing or logical selection, we can pass an array or Series of True/False values to the .loc indexer to select the rows where the Series has True values. Then, we will make selections based on the values of different columns in dataset.\n","\n","\n","We can use a boolean True/False series to select rows in a pandas dataframe where there are true values. Then, a second argument can be passed to .loc indexer to select other columns of the dataframe with the same label. The columns are referred to by name for the loc indexer and can be a single string, a list of columns, or a slice \":\" operation."]},{"cell_type":"code","execution_count":25,"metadata":{"trusted":true},"outputs":[],"source":["# make a copy of dataframe df\n","\n","df2 = df.copy()"]},{"cell_type":"code","execution_count":26,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>User_ID</th>\n","      <th>Product_ID</th>\n","      <th>Gender</th>\n","      <th>Age</th>\n","      <th>Occupation</th>\n","      <th>City_Category</th>\n","      <th>Stay_In_Current_City_Years</th>\n","      <th>Marital_Status</th>\n","      <th>Product_Category_1</th>\n","      <th>Product_Category_2</th>\n","      <th>Product_Category_3</th>\n","      <th>Purchase</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1000001</td>\n","      <td>P00069042</td>\n","      <td>F</td>\n","      <td>0-17</td>\n","      <td>10</td>\n","      <td>A</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>6.0</td>\n","      <td>14.0</td>\n","      <td>8370</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1000001</td>\n","      <td>P00248942</td>\n","      <td>F</td>\n","      <td>0-17</td>\n","      <td>10</td>\n","      <td>A</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>6.0</td>\n","      <td>14.0</td>\n","      <td>15200</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1000001</td>\n","      <td>P00087842</td>\n","      <td>F</td>\n","      <td>0-17</td>\n","      <td>10</td>\n","      <td>A</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>12</td>\n","      <td>6.0</td>\n","      <td>14.0</td>\n","      <td>1422</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1000001</td>\n","      <td>P00085442</td>\n","      <td>F</td>\n","      <td>0-17</td>\n","      <td>10</td>\n","      <td>A</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>12</td>\n","      <td>14.0</td>\n","      <td>14.0</td>\n","      <td>1057</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1000002</td>\n","      <td>P00285442</td>\n","      <td>M</td>\n","      <td>55+</td>\n","      <td>16</td>\n","      <td>C</td>\n","      <td>4+</td>\n","      <td>0</td>\n","      <td>8</td>\n","      <td>14.0</td>\n","      <td>14.0</td>\n","      <td>7969</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   User_ID Product_ID Gender   Age  Occupation City_Category  \\\n","0  1000001  P00069042      F  0-17          10             A   \n","1  1000001  P00248942      F  0-17          10             A   \n","2  1000001  P00087842      F  0-17          10             A   \n","3  1000001  P00085442      F  0-17          10             A   \n","4  1000002  P00285442      M   55+          16             C   \n","\n","  Stay_In_Current_City_Years  Marital_Status  Product_Category_1  \\\n","0                          2               0                   3   \n","1                          2               0                   1   \n","2                          2               0                  12   \n","3                          2               0                  12   \n","4                         4+               0                   8   \n","\n","   Product_Category_2  Product_Category_3  Purchase  \n","0                 6.0                14.0      8370  \n","1                 6.0                14.0     15200  \n","2                 6.0                14.0      1422  \n","3                14.0                14.0      1057  \n","4                14.0                14.0      7969  "]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["df2.head()"]},{"cell_type":"code","execution_count":27,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["0    8370\n","Name: Purchase, dtype: int64"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["# get the purchase amount with a given user_id and product_id\n","\n","df2.loc[((df2['User_ID'] == 1000001) & (df2['Product_ID'] == 'P00069042')), 'Purchase']"]},{"cell_type":"markdown","metadata":{},"source":["### Indexing with isin() method\n","\n","\n","The **isin()** method of Series, returns a boolean vector. It is true wherever the Series elements exist in the passed list. This allows you to select rows where one or more columns have values we want to access. The same method is available for Index objects. It is useful for the cases when we don't know which of the sought labels are in fact present.\n","\n","\n","DataFrame also has an **isin()** method. When calling isin, we pass a set of values as either an array or dict. If values is an array, isin returns a DataFrame of booleans that is the same shape as the original DataFrame, with True wherever the element is in the sequence of values."]},{"cell_type":"code","execution_count":28,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>User_ID</th>\n","      <th>Product_ID</th>\n","      <th>Gender</th>\n","      <th>Age</th>\n","      <th>Occupation</th>\n","      <th>City_Category</th>\n","      <th>Stay_In_Current_City_Years</th>\n","      <th>Marital_Status</th>\n","      <th>Product_Category_1</th>\n","      <th>Product_Category_2</th>\n","      <th>Product_Category_3</th>\n","      <th>Purchase</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>True</td>\n","      <td>True</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>True</td>\n","      <td>True</td>\n","      <td>True</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>True</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>True</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>True</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>True</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>True</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   User_ID  Product_ID  Gender    Age  Occupation  City_Category  \\\n","0     True        True    True  False        True           True   \n","1     True       False    True  False        True           True   \n","2     True       False    True  False        True           True   \n","3     True       False    True  False        True           True   \n","4    False       False   False  False       False          False   \n","5    False       False   False  False       False           True   \n","6    False       False   False  False       False          False   \n","7    False       False   False  False       False          False   \n","8    False       False   False  False       False          False   \n","9    False       False   False  False       False           True   \n","\n","   Stay_In_Current_City_Years  Marital_Status  Product_Category_1  \\\n","0                       False            True                True   \n","1                       False            True               False   \n","2                       False            True               False   \n","3                       False            True               False   \n","4                       False            True               False   \n","5                       False            True               False   \n","6                       False           False               False   \n","7                       False           False               False   \n","8                       False           False               False   \n","9                       False           False               False   \n","\n","   Product_Category_2  Product_Category_3  Purchase  \n","0                True                True      True  \n","1                True                True     False  \n","2                True                True     False  \n","3                True                True     False  \n","4                True                True     False  \n","5                True                True     False  \n","6               False               False     False  \n","7               False               False     False  \n","8               False               False     False  \n","9               False               False     False  "]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["values=[1000001,'P00069042','F',0-17,10,'A',2,0,3,6,14,8370]\n","\n","df2_indexed=df2.isin(values)\n","\n","\n","df2_indexed.head(10)"]},{"cell_type":"markdown","metadata":{},"source":["We can combine DataFrame's isin with the **any()** and **all()** methods to quickly select subsets of the data that meet a given criteria. We can select a row where each column meets its own criterion as follows:-"]},{"cell_type":"code","execution_count":29,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>User_ID</th>\n","      <th>Product_ID</th>\n","      <th>Gender</th>\n","      <th>Age</th>\n","      <th>Occupation</th>\n","      <th>City_Category</th>\n","      <th>Stay_In_Current_City_Years</th>\n","      <th>Marital_Status</th>\n","      <th>Product_Category_1</th>\n","      <th>Product_Category_2</th>\n","      <th>Product_Category_3</th>\n","      <th>Purchase</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1000001</td>\n","      <td>P00069042</td>\n","      <td>F</td>\n","      <td>0-17</td>\n","      <td>10</td>\n","      <td>A</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>6.0</td>\n","      <td>14.0</td>\n","      <td>8370</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1000001</td>\n","      <td>P00248942</td>\n","      <td>F</td>\n","      <td>0-17</td>\n","      <td>10</td>\n","      <td>A</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>6.0</td>\n","      <td>14.0</td>\n","      <td>15200</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1000001</td>\n","      <td>P00087842</td>\n","      <td>F</td>\n","      <td>0-17</td>\n","      <td>10</td>\n","      <td>A</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>12</td>\n","      <td>6.0</td>\n","      <td>14.0</td>\n","      <td>1422</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1000001</td>\n","      <td>P00085442</td>\n","      <td>F</td>\n","      <td>0-17</td>\n","      <td>10</td>\n","      <td>A</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>12</td>\n","      <td>14.0</td>\n","      <td>14.0</td>\n","      <td>1057</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1000002</td>\n","      <td>P00285442</td>\n","      <td>M</td>\n","      <td>55+</td>\n","      <td>16</td>\n","      <td>C</td>\n","      <td>4+</td>\n","      <td>0</td>\n","      <td>8</td>\n","      <td>14.0</td>\n","      <td>14.0</td>\n","      <td>7969</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>550063</th>\n","      <td>1006033</td>\n","      <td>P00372445</td>\n","      <td>M</td>\n","      <td>51-55</td>\n","      <td>13</td>\n","      <td>B</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>20</td>\n","      <td>2.0</td>\n","      <td>11.0</td>\n","      <td>368</td>\n","    </tr>\n","    <tr>\n","      <th>550064</th>\n","      <td>1006035</td>\n","      <td>P00375436</td>\n","      <td>F</td>\n","      <td>26-35</td>\n","      <td>1</td>\n","      <td>C</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>20</td>\n","      <td>2.0</td>\n","      <td>11.0</td>\n","      <td>371</td>\n","    </tr>\n","    <tr>\n","      <th>550065</th>\n","      <td>1006036</td>\n","      <td>P00375436</td>\n","      <td>F</td>\n","      <td>26-35</td>\n","      <td>15</td>\n","      <td>B</td>\n","      <td>4+</td>\n","      <td>1</td>\n","      <td>20</td>\n","      <td>2.0</td>\n","      <td>11.0</td>\n","      <td>137</td>\n","    </tr>\n","    <tr>\n","      <th>550066</th>\n","      <td>1006038</td>\n","      <td>P00375436</td>\n","      <td>F</td>\n","      <td>55+</td>\n","      <td>1</td>\n","      <td>C</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>20</td>\n","      <td>2.0</td>\n","      <td>11.0</td>\n","      <td>365</td>\n","    </tr>\n","    <tr>\n","      <th>550067</th>\n","      <td>1006039</td>\n","      <td>P00371644</td>\n","      <td>F</td>\n","      <td>46-50</td>\n","      <td>0</td>\n","      <td>B</td>\n","      <td>4+</td>\n","      <td>1</td>\n","      <td>20</td>\n","      <td>2.0</td>\n","      <td>11.0</td>\n","      <td>490</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>509212 rows × 12 columns</p>\n","</div>"],"text/plain":["        User_ID Product_ID Gender    Age  Occupation City_Category  \\\n","0       1000001  P00069042      F   0-17          10             A   \n","1       1000001  P00248942      F   0-17          10             A   \n","2       1000001  P00087842      F   0-17          10             A   \n","3       1000001  P00085442      F   0-17          10             A   \n","4       1000002  P00285442      M    55+          16             C   \n","...         ...        ...    ...    ...         ...           ...   \n","550063  1006033  P00372445      M  51-55          13             B   \n","550064  1006035  P00375436      F  26-35           1             C   \n","550065  1006036  P00375436      F  26-35          15             B   \n","550066  1006038  P00375436      F    55+           1             C   \n","550067  1006039  P00371644      F  46-50           0             B   \n","\n","       Stay_In_Current_City_Years  Marital_Status  Product_Category_1  \\\n","0                               2               0                   3   \n","1                               2               0                   1   \n","2                               2               0                  12   \n","3                               2               0                  12   \n","4                              4+               0                   8   \n","...                           ...             ...                 ...   \n","550063                          1               1                  20   \n","550064                          3               0                  20   \n","550065                         4+               1                  20   \n","550066                          2               0                  20   \n","550067                         4+               1                  20   \n","\n","        Product_Category_2  Product_Category_3  Purchase  \n","0                      6.0                14.0      8370  \n","1                      6.0                14.0     15200  \n","2                      6.0                14.0      1422  \n","3                     14.0                14.0      1057  \n","4                     14.0                14.0      7969  \n","...                    ...                 ...       ...  \n","550063                 2.0                11.0       368  \n","550064                 2.0                11.0       371  \n","550065                 2.0                11.0       137  \n","550066                 2.0                11.0       365  \n","550067                 2.0                11.0       490  \n","\n","[509212 rows x 12 columns]"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["row_mask = df2.isin(values).any(1)\n","\n","df[row_mask]"]},{"cell_type":"markdown","metadata":{},"source":["### The where() method and masking\n","\n","\n","We can select values from a Series with a boolean vector and it returns a subset of the data. To guarantee that the output \n","has the same shape as the original data, we can use the where method in Series and DataFrame.\n","\n","\n","We can select values from a DataFrame with a boolean criterion. It also preserves input data shape.\n","\n","\n","The  below code is equivalent to \n","\n","\n","`df2[df2==0]`\n","\n","\n","It replaces values with `NaN` where the condition is false. \n"]},{"cell_type":"code","execution_count":30,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>User_ID</th>\n","      <th>Product_ID</th>\n","      <th>Gender</th>\n","      <th>Age</th>\n","      <th>Occupation</th>\n","      <th>City_Category</th>\n","      <th>Stay_In_Current_City_Years</th>\n","      <th>Marital_Status</th>\n","      <th>Product_Category_1</th>\n","      <th>Product_Category_2</th>\n","      <th>Product_Category_3</th>\n","      <th>Purchase</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   User_ID Product_ID Gender  Age  Occupation City_Category  \\\n","0      NaN        NaN    NaN  NaN         NaN           NaN   \n","1      NaN        NaN    NaN  NaN         NaN           NaN   \n","2      NaN        NaN    NaN  NaN         NaN           NaN   \n","3      NaN        NaN    NaN  NaN         NaN           NaN   \n","4      NaN        NaN    NaN  NaN         NaN           NaN   \n","5      NaN        NaN    NaN  NaN         NaN           NaN   \n","6      NaN        NaN    NaN  NaN         NaN           NaN   \n","7      NaN        NaN    NaN  NaN         NaN           NaN   \n","8      NaN        NaN    NaN  NaN         NaN           NaN   \n","9      NaN        NaN    NaN  NaN         NaN           NaN   \n","\n","  Stay_In_Current_City_Years  Marital_Status  Product_Category_1  \\\n","0                        NaN             0.0                 NaN   \n","1                        NaN             0.0                 NaN   \n","2                        NaN             0.0                 NaN   \n","3                        NaN             0.0                 NaN   \n","4                        NaN             0.0                 NaN   \n","5                        NaN             0.0                 NaN   \n","6                        NaN             NaN                 NaN   \n","7                        NaN             NaN                 NaN   \n","8                        NaN             NaN                 NaN   \n","9                        NaN             NaN                 NaN   \n","\n","   Product_Category_2  Product_Category_3  Purchase  \n","0                 NaN                 NaN       NaN  \n","1                 NaN                 NaN       NaN  \n","2                 NaN                 NaN       NaN  \n","3                 NaN                 NaN       NaN  \n","4                 NaN                 NaN       NaN  \n","5                 NaN                 NaN       NaN  \n","6                 NaN                 NaN       NaN  \n","7                 NaN                 NaN       NaN  \n","8                 NaN                 NaN       NaN  \n","9                 NaN                 NaN       NaN  "]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["df2_where=df2.where(df2 == 0)\n","\n","\n","(df2_where).head(10)"]},{"cell_type":"markdown","metadata":{},"source":["###  Indexing with query() method\n","\n","\n","There is a **query()** method in the DataFrame objects that allows selection using an expression. This method queries the columns of a DataFrame with a boolean expression.\n"]},{"cell_type":"code","execution_count":31,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>User_ID</th>\n","      <th>Product_ID</th>\n","      <th>Gender</th>\n","      <th>Age</th>\n","      <th>Occupation</th>\n","      <th>City_Category</th>\n","      <th>Stay_In_Current_City_Years</th>\n","      <th>Marital_Status</th>\n","      <th>Product_Category_1</th>\n","      <th>Product_Category_2</th>\n","      <th>Product_Category_3</th>\n","      <th>Purchase</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>165</th>\n","      <td>1000033</td>\n","      <td>P00111742</td>\n","      <td>M</td>\n","      <td>46-50</td>\n","      <td>3</td>\n","      <td>A</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>15</td>\n","      <td>8.0</td>\n","      <td>5.0</td>\n","      <td>17391</td>\n","    </tr>\n","    <tr>\n","      <th>304</th>\n","      <td>1000053</td>\n","      <td>P00117542</td>\n","      <td>M</td>\n","      <td>26-35</td>\n","      <td>0</td>\n","      <td>B</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>18</td>\n","      <td>16.0</td>\n","      <td>5.0</td>\n","      <td>3794</td>\n","    </tr>\n","    <tr>\n","      <th>351</th>\n","      <td>1000058</td>\n","      <td>P00288642</td>\n","      <td>M</td>\n","      <td>26-35</td>\n","      <td>2</td>\n","      <td>B</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>16</td>\n","      <td>14.0</td>\n","      <td>12.0</td>\n","      <td>16579</td>\n","    </tr>\n","    <tr>\n","      <th>387</th>\n","      <td>1000062</td>\n","      <td>P00087242</td>\n","      <td>F</td>\n","      <td>36-45</td>\n","      <td>3</td>\n","      <td>A</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>14</td>\n","      <td>12.0</td>\n","      <td>6.0</td>\n","      <td>11279</td>\n","    </tr>\n","    <tr>\n","      <th>724</th>\n","      <td>1000137</td>\n","      <td>P00124642</td>\n","      <td>F</td>\n","      <td>46-50</td>\n","      <td>6</td>\n","      <td>C</td>\n","      <td>4+</td>\n","      <td>1</td>\n","      <td>16</td>\n","      <td>14.0</td>\n","      <td>6.0</td>\n","      <td>16828</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>545338</th>\n","      <td>1005954</td>\n","      <td>P00327342</td>\n","      <td>M</td>\n","      <td>46-50</td>\n","      <td>11</td>\n","      <td>A</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>16</td>\n","      <td>11.0</td>\n","      <td>5.0</td>\n","      <td>12330</td>\n","    </tr>\n","    <tr>\n","      <th>545339</th>\n","      <td>1005954</td>\n","      <td>P00087842</td>\n","      <td>M</td>\n","      <td>46-50</td>\n","      <td>11</td>\n","      <td>A</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>12</td>\n","      <td>11.0</td>\n","      <td>5.0</td>\n","      <td>343</td>\n","    </tr>\n","    <tr>\n","      <th>545461</th>\n","      <td>1005972</td>\n","      <td>P00255842</td>\n","      <td>F</td>\n","      <td>26-35</td>\n","      <td>20</td>\n","      <td>B</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>16</td>\n","      <td>11.0</td>\n","      <td>5.0</td>\n","      <td>20634</td>\n","    </tr>\n","    <tr>\n","      <th>545747</th>\n","      <td>1006016</td>\n","      <td>P00058642</td>\n","      <td>M</td>\n","      <td>46-50</td>\n","      <td>1</td>\n","      <td>B</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>18</td>\n","      <td>14.0</td>\n","      <td>12.0</td>\n","      <td>3018</td>\n","    </tr>\n","    <tr>\n","      <th>545896</th>\n","      <td>1006037</td>\n","      <td>P00183142</td>\n","      <td>F</td>\n","      <td>46-50</td>\n","      <td>1</td>\n","      <td>C</td>\n","      <td>4+</td>\n","      <td>0</td>\n","      <td>15</td>\n","      <td>14.0</td>\n","      <td>13.0</td>\n","      <td>13054</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2278 rows × 12 columns</p>\n","</div>"],"text/plain":["        User_ID Product_ID Gender    Age  Occupation City_Category  \\\n","165     1000033  P00111742      M  46-50           3             A   \n","304     1000053  P00117542      M  26-35           0             B   \n","351     1000058  P00288642      M  26-35           2             B   \n","387     1000062  P00087242      F  36-45           3             A   \n","724     1000137  P00124642      F  46-50           6             C   \n","...         ...        ...    ...    ...         ...           ...   \n","545338  1005954  P00327342      M  46-50          11             A   \n","545339  1005954  P00087842      M  46-50          11             A   \n","545461  1005972  P00255842      F  26-35          20             B   \n","545747  1006016  P00058642      M  46-50           1             B   \n","545896  1006037  P00183142      F  46-50           1             C   \n","\n","       Stay_In_Current_City_Years  Marital_Status  Product_Category_1  \\\n","165                             1               1                  15   \n","304                             1               0                  18   \n","351                             3               0                  16   \n","387                             1               0                  14   \n","724                            4+               1                  16   \n","...                           ...             ...                 ...   \n","545338                          2               1                  16   \n","545339                          2               1                  12   \n","545461                          0               0                  16   \n","545747                          1               1                  18   \n","545896                         4+               0                  15   \n","\n","        Product_Category_2  Product_Category_3  Purchase  \n","165                    8.0                 5.0     17391  \n","304                   16.0                 5.0      3794  \n","351                   14.0                12.0     16579  \n","387                   12.0                 6.0     11279  \n","724                   14.0                 6.0     16828  \n","...                    ...                 ...       ...  \n","545338                11.0                 5.0     12330  \n","545339                11.0                 5.0       343  \n","545461                11.0                 5.0     20634  \n","545747                14.0                12.0      3018  \n","545896                14.0                13.0     13054  \n","\n","[2278 rows x 12 columns]"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["df2.query('(Product_Category_1 > Product_Category_2) & (Product_Category_2 > Product_Category_3)')"]},{"cell_type":"markdown","metadata":{},"source":["# 13. Indexing and reindexing in pandas <a class=\"anchor\" id=\"13\"></a>\n","\n","\n","[Back to Table of Contents](#0.1)\n","\n","\n","Reindexing changes the row labels and column labels of a DataFrame. To reindex means to conform the data to match \n","a given set of labels along a particular axis.\n","\n","\n","Multiple operations can be accomplished through indexing like :−\n","\n","\n","- Reorder the existing data to match a new set of labels.\n","\n","\n","- Insert missing value (NA) markers in label locations where no data for the label existed."]},{"cell_type":"markdown","metadata":{},"source":["### Create a new dataframe\n","\n","\n","First of all, I will create a new dataframe as follows:- "]},{"cell_type":"code","execution_count":32,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Place</th>\n","      <th>Time</th>\n","      <th>Food</th>\n","      <th>Price($)</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Home</td>\n","      <td>Lunch</td>\n","      <td>Soup</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Home</td>\n","      <td>Dinner</td>\n","      <td>Rice</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Hotel</td>\n","      <td>Lunch</td>\n","      <td>Soup</td>\n","      <td>30</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Hotel</td>\n","      <td>Dinner</td>\n","      <td>Chapati</td>\n","      <td>40</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Place    Time     Food  Price($)\n","0   Home   Lunch     Soup        10\n","1   Home  Dinner     Rice        20\n","2  Hotel   Lunch     Soup        30\n","3  Hotel  Dinner  Chapati        40"]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["# let's create a new dataframe \n","\n","food = pd.DataFrame({'Place':['Home', 'Home', 'Hotel', 'Hotel'],\n","                   'Time': ['Lunch', 'Dinner', 'Lunch', 'Dinner'],\n","                   'Food':['Soup', 'Rice', 'Soup', 'Chapati'],\n","                   'Price($)':[10, 20, 30, 40]})\n","\n","food"]},{"cell_type":"markdown","metadata":{},"source":["### Set an index \n","\n","\n","DataFrame has a **set_index()** method which takes a column name (for a regular Index) or a list of column names (for a MultiIndex). This method sets the dataframe index using existing columns.\n","\n","I will create a new, re-indexed DataFrame with **set_index()** method as follows:-"]},{"cell_type":"code","execution_count":33,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Time</th>\n","      <th>Food</th>\n","      <th>Price($)</th>\n","    </tr>\n","    <tr>\n","      <th>Place</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Home</th>\n","      <td>Lunch</td>\n","      <td>Soup</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>Home</th>\n","      <td>Dinner</td>\n","      <td>Rice</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>Hotel</th>\n","      <td>Lunch</td>\n","      <td>Soup</td>\n","      <td>30</td>\n","    </tr>\n","    <tr>\n","      <th>Hotel</th>\n","      <td>Dinner</td>\n","      <td>Chapati</td>\n","      <td>40</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         Time     Food  Price($)\n","Place                           \n","Home    Lunch     Soup        10\n","Home   Dinner     Rice        20\n","Hotel   Lunch     Soup        30\n","Hotel  Dinner  Chapati        40"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["food_indexed1=food.set_index('Place')\n","\n","food_indexed1"]},{"cell_type":"code","execution_count":34,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th></th>\n","      <th>Food</th>\n","      <th>Price($)</th>\n","    </tr>\n","    <tr>\n","      <th>Place</th>\n","      <th>Time</th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th rowspan=\"2\" valign=\"top\">Home</th>\n","      <th>Lunch</th>\n","      <td>Soup</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>Dinner</th>\n","      <td>Rice</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"2\" valign=\"top\">Hotel</th>\n","      <th>Lunch</th>\n","      <td>Soup</td>\n","      <td>30</td>\n","    </tr>\n","    <tr>\n","      <th>Dinner</th>\n","      <td>Chapati</td>\n","      <td>40</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                 Food  Price($)\n","Place Time                     \n","Home  Lunch      Soup        10\n","      Dinner     Rice        20\n","Hotel Lunch      Soup        30\n","      Dinner  Chapati        40"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["food_indexed2=food.set_index(['Place', 'Time'])\n","\n","food_indexed2"]},{"cell_type":"markdown","metadata":{},"source":["### Reset the index\n","\n","\n","There is a function called **reset_index()** which transfers the index values into the DataFrame’s columns and sets a simple integer index. This is the inverse operation of set_index()."]},{"cell_type":"code","execution_count":35,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Place</th>\n","      <th>Time</th>\n","      <th>Food</th>\n","      <th>Price($)</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Home</td>\n","      <td>Lunch</td>\n","      <td>Soup</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Home</td>\n","      <td>Dinner</td>\n","      <td>Rice</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Hotel</td>\n","      <td>Lunch</td>\n","      <td>Soup</td>\n","      <td>30</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Hotel</td>\n","      <td>Dinner</td>\n","      <td>Chapati</td>\n","      <td>40</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Place    Time     Food  Price($)\n","0   Home   Lunch     Soup        10\n","1   Home  Dinner     Rice        20\n","2  Hotel   Lunch     Soup        30\n","3  Hotel  Dinner  Chapati        40"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["food_indexed2.reset_index()"]},{"cell_type":"markdown","metadata":{},"source":["# 14. MultiIndex or advanced indexing <a class=\"anchor\" id=\"14\"></a>\n","\n","\n","[Back to Table of Contents](#0.1)\n","\n","\n","In this section, I will explore indexing with a MultiIndex and other advanced indexing strategies.\n","\n","\n","\n","\n","### Hierarchical indexing  or MultiIndex\n","\n","\n","\n","The MultiIndex object is the hierarchical analogue of the standard index object which stores the axis labels in pandas objects. A MultiIndex is an array of tuples where each tuple is unique. A MultiIndex can be created from a list of arrays (using **MultiIndex.from_arrays()**), an array of tuples (using **MultiIndex.from_tuples()**), a crossed set of iterables (using **MultiIndex.from_product()**), or a DataFrame (using **MultiIndex.from_frame()**). The Index constructor will attempt to return a MultiIndex when it is passed a list of tuples.\n","\n","\n","To demonstrate the concept of hierarchical or multiple indexing, first I will create a hypothetical dataframe as follows:- "]},{"cell_type":"code","execution_count":36,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Items</th>\n","      <th>Mode</th>\n","      <th>Price</th>\n","      <th>Profit</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>books</td>\n","      <td>online</td>\n","      <td>200</td>\n","      <td>50</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>books</td>\n","      <td>retail</td>\n","      <td>250</td>\n","      <td>75</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>toys</td>\n","      <td>online</td>\n","      <td>100</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>toys</td>\n","      <td>retail</td>\n","      <td>140</td>\n","      <td>30</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>watches</td>\n","      <td>online</td>\n","      <td>500</td>\n","      <td>100</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>watches</td>\n","      <td>retail</td>\n","      <td>600</td>\n","      <td>150</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>computers</td>\n","      <td>online</td>\n","      <td>1000</td>\n","      <td>200</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>computers</td>\n","      <td>retail</td>\n","      <td>1200</td>\n","      <td>300</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>laptops</td>\n","      <td>online</td>\n","      <td>1100</td>\n","      <td>400</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>laptops</td>\n","      <td>retail</td>\n","      <td>1400</td>\n","      <td>500</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>smartphones</td>\n","      <td>online</td>\n","      <td>600</td>\n","      <td>200</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>smartphones</td>\n","      <td>retail</td>\n","      <td>800</td>\n","      <td>250</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          Items    Mode  Price  Profit\n","0         books  online    200      50\n","1         books  retail    250      75\n","2          toys  online    100      20\n","3          toys  retail    140      30\n","4       watches  online    500     100\n","5       watches  retail    600     150\n","6     computers  online   1000     200\n","7     computers  retail   1200     300\n","8       laptops  online   1100     400\n","9       laptops  retail   1400     500\n","10  smartphones  online    600     200\n","11  smartphones  retail    800     250"]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["sales=pd.DataFrame([['books','online', 200, 50],['books','retail', 250, 75], \n","                    ['toys','online', 100, 20],['toys','retail', 140, 30],\n","                    ['watches','online', 500, 100],['watches','retail', 600, 150],\n","                    ['computers','online', 1000, 200],['computers','retail', 1200, 300],\n","                    ['laptops','online', 1100, 400],['laptops','retail', 1400, 500],\n","                    ['smartphones','online', 600, 200],['smartphones','retail', 800, 250]],\n","                    columns=['Items', 'Mode', 'Price', 'Profit'])\n","\n","\n","sales"]},{"cell_type":"markdown","metadata":{},"source":["### Create the hierarchical index in pandas\n","\n","\n","We can create a hierarchical index in pandas using the **set_index()** function which is used for indexing. First the data is indexed on `Items` and then on `Mode` column as follows:-"]},{"cell_type":"code","execution_count":37,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th></th>\n","      <th>Price</th>\n","      <th>Profit</th>\n","    </tr>\n","    <tr>\n","      <th>Items</th>\n","      <th>Mode</th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th rowspan=\"2\" valign=\"top\">books</th>\n","      <th>online</th>\n","      <td>200</td>\n","      <td>50</td>\n","    </tr>\n","    <tr>\n","      <th>retail</th>\n","      <td>250</td>\n","      <td>75</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"2\" valign=\"top\">toys</th>\n","      <th>online</th>\n","      <td>100</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>retail</th>\n","      <td>140</td>\n","      <td>30</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"2\" valign=\"top\">watches</th>\n","      <th>online</th>\n","      <td>500</td>\n","      <td>100</td>\n","    </tr>\n","    <tr>\n","      <th>retail</th>\n","      <td>600</td>\n","      <td>150</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"2\" valign=\"top\">computers</th>\n","      <th>online</th>\n","      <td>1000</td>\n","      <td>200</td>\n","    </tr>\n","    <tr>\n","      <th>retail</th>\n","      <td>1200</td>\n","      <td>300</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"2\" valign=\"top\">laptops</th>\n","      <th>online</th>\n","      <td>1100</td>\n","      <td>400</td>\n","    </tr>\n","    <tr>\n","      <th>retail</th>\n","      <td>1400</td>\n","      <td>500</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"2\" valign=\"top\">smartphones</th>\n","      <th>online</th>\n","      <td>600</td>\n","      <td>200</td>\n","    </tr>\n","    <tr>\n","      <th>retail</th>\n","      <td>800</td>\n","      <td>250</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                    Price  Profit\n","Items       Mode                 \n","books       online    200      50\n","            retail    250      75\n","toys        online    100      20\n","            retail    140      30\n","watches     online    500     100\n","            retail    600     150\n","computers   online   1000     200\n","            retail   1200     300\n","laptops     online   1100     400\n","            retail   1400     500\n","smartphones online    600     200\n","            retail    800     250"]},"execution_count":37,"metadata":{},"output_type":"execute_result"}],"source":["sales1=sales.set_index(['Items', 'Mode'])\n","\n","sales1"]},{"cell_type":"markdown","metadata":{},"source":[" The resultant dataframe will be a hierarchical dataframe as shown above."]},{"cell_type":"markdown","metadata":{},"source":["### View index in hierarchical index\n","\n","\n","One can view the details of index as shown below:-"]},{"cell_type":"code","execution_count":38,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["MultiIndex([(      'books', 'online'),\n","            (      'books', 'retail'),\n","            (       'toys', 'online'),\n","            (       'toys', 'retail'),\n","            (    'watches', 'online'),\n","            (    'watches', 'retail'),\n","            (  'computers', 'online'),\n","            (  'computers', 'retail'),\n","            (    'laptops', 'online'),\n","            (    'laptops', 'retail'),\n","            ('smartphones', 'online'),\n","            ('smartphones', 'retail')],\n","           names=['Items', 'Mode'])"]},"execution_count":38,"metadata":{},"output_type":"execute_result"}],"source":["# View index\n","\n","sales1.index"]},{"cell_type":"markdown","metadata":{},"source":["### Swap the column in hierarchical index\n","\n","\n","Now, I will swap the \"Items\" and \"Mode\" columns in the above hierarchical dataframe as shown below:-"]},{"cell_type":"code","execution_count":39,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th></th>\n","      <th>Price</th>\n","      <th>Profit</th>\n","    </tr>\n","    <tr>\n","      <th>Mode</th>\n","      <th>Items</th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>online</th>\n","      <th>books</th>\n","      <td>200</td>\n","      <td>50</td>\n","    </tr>\n","    <tr>\n","      <th>retail</th>\n","      <th>books</th>\n","      <td>250</td>\n","      <td>75</td>\n","    </tr>\n","    <tr>\n","      <th>online</th>\n","      <th>toys</th>\n","      <td>100</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>retail</th>\n","      <th>toys</th>\n","      <td>140</td>\n","      <td>30</td>\n","    </tr>\n","    <tr>\n","      <th>online</th>\n","      <th>watches</th>\n","      <td>500</td>\n","      <td>100</td>\n","    </tr>\n","    <tr>\n","      <th>retail</th>\n","      <th>watches</th>\n","      <td>600</td>\n","      <td>150</td>\n","    </tr>\n","    <tr>\n","      <th>online</th>\n","      <th>computers</th>\n","      <td>1000</td>\n","      <td>200</td>\n","    </tr>\n","    <tr>\n","      <th>retail</th>\n","      <th>computers</th>\n","      <td>1200</td>\n","      <td>300</td>\n","    </tr>\n","    <tr>\n","      <th>online</th>\n","      <th>laptops</th>\n","      <td>1100</td>\n","      <td>400</td>\n","    </tr>\n","    <tr>\n","      <th>retail</th>\n","      <th>laptops</th>\n","      <td>1400</td>\n","      <td>500</td>\n","    </tr>\n","    <tr>\n","      <th>online</th>\n","      <th>smartphones</th>\n","      <td>600</td>\n","      <td>200</td>\n","    </tr>\n","    <tr>\n","      <th>retail</th>\n","      <th>smartphones</th>\n","      <td>800</td>\n","      <td>250</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                    Price  Profit\n","Mode   Items                     \n","online books          200      50\n","retail books          250      75\n","online toys           100      20\n","retail toys           140      30\n","online watches        500     100\n","retail watches        600     150\n","online computers     1000     200\n","retail computers     1200     300\n","online laptops       1100     400\n","retail laptops       1400     500\n","online smartphones    600     200\n","retail smartphones    800     250"]},"execution_count":39,"metadata":{},"output_type":"execute_result"}],"source":["# Swap the column  in multiple index\n","\n","sales2=sales1.swaplevel('Mode', 'Items')\n","\n","sales2"]},{"cell_type":"markdown","metadata":{},"source":["# 15. Sorting in pandas <a class=\"anchor\" id=\"15\"></a>\n","\n","\n","[Back to Table of Contents](#0.1)\n","\n","\n","Pandas provides two kinds of sorting. They are:-\n","\n","\n","- 1. Sorting by label\n","\n","- 2. Sorting by actual value\n","\n","\n","They are described below:-\n"]},{"cell_type":"markdown","metadata":{},"source":["### 1. Sorting by label\n","\n","\n","We can use the **sort_index()** method to sort the object by labels. DataFrame can be sorted by passing the axis arguments and the order of sorting. By default, sorting is done on row labels in ascending order.\n","\n","\n","The following examples illustrate the idea of sorting by label."]},{"cell_type":"code","execution_count":40,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>User_ID</th>\n","      <th>Product_ID</th>\n","      <th>Gender</th>\n","      <th>Age</th>\n","      <th>Occupation</th>\n","      <th>City_Category</th>\n","      <th>Stay_In_Current_City_Years</th>\n","      <th>Marital_Status</th>\n","      <th>Product_Category_1</th>\n","      <th>Product_Category_2</th>\n","      <th>Product_Category_3</th>\n","      <th>Purchase</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1000001</td>\n","      <td>P00069042</td>\n","      <td>F</td>\n","      <td>0-17</td>\n","      <td>10</td>\n","      <td>A</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>6.0</td>\n","      <td>14.0</td>\n","      <td>8370</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1000001</td>\n","      <td>P00248942</td>\n","      <td>F</td>\n","      <td>0-17</td>\n","      <td>10</td>\n","      <td>A</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>6.0</td>\n","      <td>14.0</td>\n","      <td>15200</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1000001</td>\n","      <td>P00087842</td>\n","      <td>F</td>\n","      <td>0-17</td>\n","      <td>10</td>\n","      <td>A</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>12</td>\n","      <td>6.0</td>\n","      <td>14.0</td>\n","      <td>1422</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1000001</td>\n","      <td>P00085442</td>\n","      <td>F</td>\n","      <td>0-17</td>\n","      <td>10</td>\n","      <td>A</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>12</td>\n","      <td>14.0</td>\n","      <td>14.0</td>\n","      <td>1057</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1000002</td>\n","      <td>P00285442</td>\n","      <td>M</td>\n","      <td>55+</td>\n","      <td>16</td>\n","      <td>C</td>\n","      <td>4+</td>\n","      <td>0</td>\n","      <td>8</td>\n","      <td>14.0</td>\n","      <td>14.0</td>\n","      <td>7969</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>550063</th>\n","      <td>1006033</td>\n","      <td>P00372445</td>\n","      <td>M</td>\n","      <td>51-55</td>\n","      <td>13</td>\n","      <td>B</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>20</td>\n","      <td>2.0</td>\n","      <td>11.0</td>\n","      <td>368</td>\n","    </tr>\n","    <tr>\n","      <th>550064</th>\n","      <td>1006035</td>\n","      <td>P00375436</td>\n","      <td>F</td>\n","      <td>26-35</td>\n","      <td>1</td>\n","      <td>C</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>20</td>\n","      <td>2.0</td>\n","      <td>11.0</td>\n","      <td>371</td>\n","    </tr>\n","    <tr>\n","      <th>550065</th>\n","      <td>1006036</td>\n","      <td>P00375436</td>\n","      <td>F</td>\n","      <td>26-35</td>\n","      <td>15</td>\n","      <td>B</td>\n","      <td>4+</td>\n","      <td>1</td>\n","      <td>20</td>\n","      <td>2.0</td>\n","      <td>11.0</td>\n","      <td>137</td>\n","    </tr>\n","    <tr>\n","      <th>550066</th>\n","      <td>1006038</td>\n","      <td>P00375436</td>\n","      <td>F</td>\n","      <td>55+</td>\n","      <td>1</td>\n","      <td>C</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>20</td>\n","      <td>2.0</td>\n","      <td>11.0</td>\n","      <td>365</td>\n","    </tr>\n","    <tr>\n","      <th>550067</th>\n","      <td>1006039</td>\n","      <td>P00371644</td>\n","      <td>F</td>\n","      <td>46-50</td>\n","      <td>0</td>\n","      <td>B</td>\n","      <td>4+</td>\n","      <td>1</td>\n","      <td>20</td>\n","      <td>2.0</td>\n","      <td>11.0</td>\n","      <td>490</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>550068 rows × 12 columns</p>\n","</div>"],"text/plain":["        User_ID Product_ID Gender    Age  Occupation City_Category  \\\n","0       1000001  P00069042      F   0-17          10             A   \n","1       1000001  P00248942      F   0-17          10             A   \n","2       1000001  P00087842      F   0-17          10             A   \n","3       1000001  P00085442      F   0-17          10             A   \n","4       1000002  P00285442      M    55+          16             C   \n","...         ...        ...    ...    ...         ...           ...   \n","550063  1006033  P00372445      M  51-55          13             B   \n","550064  1006035  P00375436      F  26-35           1             C   \n","550065  1006036  P00375436      F  26-35          15             B   \n","550066  1006038  P00375436      F    55+           1             C   \n","550067  1006039  P00371644      F  46-50           0             B   \n","\n","       Stay_In_Current_City_Years  Marital_Status  Product_Category_1  \\\n","0                               2               0                   3   \n","1                               2               0                   1   \n","2                               2               0                  12   \n","3                               2               0                  12   \n","4                              4+               0                   8   \n","...                           ...             ...                 ...   \n","550063                          1               1                  20   \n","550064                          3               0                  20   \n","550065                         4+               1                  20   \n","550066                          2               0                  20   \n","550067                         4+               1                  20   \n","\n","        Product_Category_2  Product_Category_3  Purchase  \n","0                      6.0                14.0      8370  \n","1                      6.0                14.0     15200  \n","2                      6.0                14.0      1422  \n","3                     14.0                14.0      1057  \n","4                     14.0                14.0      7969  \n","...                    ...                 ...       ...  \n","550063                 2.0                11.0       368  \n","550064                 2.0                11.0       371  \n","550065                 2.0                11.0       137  \n","550066                 2.0                11.0       365  \n","550067                 2.0                11.0       490  \n","\n","[550068 rows x 12 columns]"]},"execution_count":40,"metadata":{},"output_type":"execute_result"}],"source":["# sort the dataframe df2 by label\n","\n","df2.sort_index()"]},{"cell_type":"markdown","metadata":{},"source":["### Order of sorting\n","\n","By passing the Boolean value to ascending parameter, the order of the sorting can be controlled. \n","\n","\n","\n","#### sort the dataframe df2 by label in reverse order\n","\n","`df2.sort_index(ascending=False)`\n","\n","\n","\n","### Sorting by columns\n","\n","\n","By passing the axis argument with a value 0 or 1, the sorting can be done on the row or column labels. \n","\n","The default value of axis=0. In this case, sorting can be done by rows. \n","\n","If we set axis=1, sorting is done by columns.\n","\n","\n","#### sort the dataframe df2 by columns\n","\n","`df2.sort_index(axis=1)`\n"]},{"cell_type":"markdown","metadata":{},"source":["### 2. Sorting by values\n","\n","\n","The second method of sorting is sorting by values. Pandas provides **sort_values()** method to sort by values. It accepts a 'by' argument which will use the column name of the DataFrame with which the values are to be sorted.\n","\n","\n","The following example illustrates the idea:-\n"]},{"cell_type":"code","execution_count":41,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>User_ID</th>\n","      <th>Product_ID</th>\n","      <th>Gender</th>\n","      <th>Age</th>\n","      <th>Occupation</th>\n","      <th>City_Category</th>\n","      <th>Stay_In_Current_City_Years</th>\n","      <th>Marital_Status</th>\n","      <th>Product_Category_1</th>\n","      <th>Product_Category_2</th>\n","      <th>Product_Category_3</th>\n","      <th>Purchase</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>271814</th>\n","      <td>1005880</td>\n","      <td>P00016042</td>\n","      <td>M</td>\n","      <td>26-35</td>\n","      <td>1</td>\n","      <td>A</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>16.0</td>\n","      <td>8.0</td>\n","      <td>8322</td>\n","    </tr>\n","    <tr>\n","      <th>208659</th>\n","      <td>1002109</td>\n","      <td>P00298942</td>\n","      <td>M</td>\n","      <td>26-35</td>\n","      <td>16</td>\n","      <td>B</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>5.0</td>\n","      <td>13.0</td>\n","      <td>7823</td>\n","    </tr>\n","    <tr>\n","      <th>436707</th>\n","      <td>1001231</td>\n","      <td>P00334242</td>\n","      <td>M</td>\n","      <td>26-35</td>\n","      <td>12</td>\n","      <td>C</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>8.0</td>\n","      <td>17.0</td>\n","      <td>15803</td>\n","    </tr>\n","    <tr>\n","      <th>108508</th>\n","      <td>1004685</td>\n","      <td>P00025442</td>\n","      <td>M</td>\n","      <td>36-45</td>\n","      <td>1</td>\n","      <td>B</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2.0</td>\n","      <td>9.0</td>\n","      <td>15647</td>\n","    </tr>\n","    <tr>\n","      <th>208658</th>\n","      <td>1002109</td>\n","      <td>P00062842</td>\n","      <td>M</td>\n","      <td>26-35</td>\n","      <td>16</td>\n","      <td>B</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2.0</td>\n","      <td>13.0</td>\n","      <td>11643</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>547638</th>\n","      <td>1002549</td>\n","      <td>P00375436</td>\n","      <td>M</td>\n","      <td>55+</td>\n","      <td>13</td>\n","      <td>C</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>20</td>\n","      <td>2.0</td>\n","      <td>11.0</td>\n","      <td>613</td>\n","    </tr>\n","    <tr>\n","      <th>547640</th>\n","      <td>1002553</td>\n","      <td>P00375436</td>\n","      <td>M</td>\n","      <td>26-35</td>\n","      <td>7</td>\n","      <td>C</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>20</td>\n","      <td>2.0</td>\n","      <td>11.0</td>\n","      <td>240</td>\n","    </tr>\n","    <tr>\n","      <th>547642</th>\n","      <td>1002556</td>\n","      <td>P00371644</td>\n","      <td>M</td>\n","      <td>26-35</td>\n","      <td>4</td>\n","      <td>C</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>20</td>\n","      <td>2.0</td>\n","      <td>11.0</td>\n","      <td>120</td>\n","    </tr>\n","    <tr>\n","      <th>547644</th>\n","      <td>1002558</td>\n","      <td>P00375436</td>\n","      <td>M</td>\n","      <td>55+</td>\n","      <td>17</td>\n","      <td>C</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>20</td>\n","      <td>2.0</td>\n","      <td>11.0</td>\n","      <td>373</td>\n","    </tr>\n","    <tr>\n","      <th>550067</th>\n","      <td>1006039</td>\n","      <td>P00371644</td>\n","      <td>F</td>\n","      <td>46-50</td>\n","      <td>0</td>\n","      <td>B</td>\n","      <td>4+</td>\n","      <td>1</td>\n","      <td>20</td>\n","      <td>2.0</td>\n","      <td>11.0</td>\n","      <td>490</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>550068 rows × 12 columns</p>\n","</div>"],"text/plain":["        User_ID Product_ID Gender    Age  Occupation City_Category  \\\n","271814  1005880  P00016042      M  26-35           1             A   \n","208659  1002109  P00298942      M  26-35          16             B   \n","436707  1001231  P00334242      M  26-35          12             C   \n","108508  1004685  P00025442      M  36-45           1             B   \n","208658  1002109  P00062842      M  26-35          16             B   \n","...         ...        ...    ...    ...         ...           ...   \n","547638  1002549  P00375436      M    55+          13             C   \n","547640  1002553  P00375436      M  26-35           7             C   \n","547642  1002556  P00371644      M  26-35           4             C   \n","547644  1002558  P00375436      M    55+          17             C   \n","550067  1006039  P00371644      F  46-50           0             B   \n","\n","       Stay_In_Current_City_Years  Marital_Status  Product_Category_1  \\\n","271814                          1               1                   1   \n","208659                          2               0                   1   \n","436707                          1               0                   1   \n","108508                          2               1                   1   \n","208658                          2               0                   1   \n","...                           ...             ...                 ...   \n","547638                          3               1                  20   \n","547640                          0               0                  20   \n","547642                          2               0                  20   \n","547644                          3               1                  20   \n","550067                         4+               1                  20   \n","\n","        Product_Category_2  Product_Category_3  Purchase  \n","271814                16.0                 8.0      8322  \n","208659                 5.0                13.0      7823  \n","436707                 8.0                17.0     15803  \n","108508                 2.0                 9.0     15647  \n","208658                 2.0                13.0     11643  \n","...                    ...                 ...       ...  \n","547638                 2.0                11.0       613  \n","547640                 2.0                11.0       240  \n","547642                 2.0                11.0       120  \n","547644                 2.0                11.0       373  \n","550067                 2.0                11.0       490  \n","\n","[550068 rows x 12 columns]"]},"execution_count":41,"metadata":{},"output_type":"execute_result"}],"source":["df2.sort_values(by=['Product_Category_1'])"]},{"cell_type":"markdown","metadata":{},"source":["#### Sort by multiple columns\n","\n","\n","`df2.sort_values(by=['Product_Category_1', 'Product_Category_2'])`\n","\n","\n","\n","\n","#### Sort in descending order\n","\n","\n","`df2.sort_values(by='Product_Category_1', ascending=False)`\n"]},{"cell_type":"markdown","metadata":{},"source":["# 16. Categorical data in pandas <a class=\"anchor\" id=\"16\"></a>\n","\n","\n","[Back to Table of Contents](#0.1)\n","\n","\n","We can check the data types of variables in the dataset with the following command:-"]},{"cell_type":"code","execution_count":42,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["User_ID                         int64\n","Product_ID                     object\n","Gender                         object\n","Age                            object\n","Occupation                      int64\n","City_Category                  object\n","Stay_In_Current_City_Years     object\n","Marital_Status                  int64\n","Product_Category_1              int64\n","Product_Category_2            float64\n","Product_Category_3            float64\n","Purchase                        int64\n","dtype: object"]},"execution_count":42,"metadata":{},"output_type":"execute_result"}],"source":["df3 = df.copy()\n","\n","df3.dtypes"]},{"cell_type":"markdown","metadata":{},"source":["We can see that our dataset has 5 categorical variables. They are **Product_ID**, **Gender**, **Age**, **City_Category** and\n","**Stay_In_Current_City_Years**. They have data types as **object**.\n","\n","Now, I will explore these categorical variables."]},{"cell_type":"markdown","metadata":{},"source":["###  Description of categorical data\n","\n","\n","The **describe()** method on categorical data will produce similar output to a Series or DataFrame of type string."]},{"cell_type":"code","execution_count":43,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["count     550068\n","unique         2\n","top            M\n","freq      414259\n","Name: Gender, dtype: object"]},"execution_count":43,"metadata":{},"output_type":"execute_result"}],"source":["df3['Gender'].describe()"]},{"cell_type":"markdown","metadata":{},"source":["The `Gender` category has 537577 counts, 2 unique values and frequency of top value M is 405380."]},{"cell_type":"code","execution_count":44,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["count     550068\n","unique         7\n","top        26-35\n","freq      219587\n","Name: Age, dtype: object"]},"execution_count":44,"metadata":{},"output_type":"execute_result"}],"source":["df3['Age'].describe()"]},{"cell_type":"markdown","metadata":{},"source":["There are 7 unique categories in `Age` variable. The most frequent category is `26-35` with frequency count of 214690."]},{"cell_type":"code","execution_count":45,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["count     550068\n","unique         3\n","top            B\n","freq      231173\n","Name: City_Category, dtype: object"]},"execution_count":45,"metadata":{},"output_type":"execute_result"}],"source":["df3['City_Category'].describe()"]},{"cell_type":"markdown","metadata":{},"source":["There are 3 unique categories in  `City_Category` variable. The most frequent category is `B` with frequency count of 226493."]},{"cell_type":"markdown","metadata":{},"source":["### Working with categorical data\n","\n","\n","Categorical data has a categories and a ordered property, which list their possible values and whether the ordering matters or not. These properties are exposed as `s.cat.categories` and `s.cat.ordered`. \n","\n","If we don't manually specify categories and ordering, they are inferred from the passed arguments.\n","\n","\n","`s.cat.categories`\n","\n","`s.cat.ordered`\n","\n","where `s` is a series object."]},{"cell_type":"markdown","metadata":{},"source":["### Unique values in categorical data\n","\n","\n","We can get the unique values in a series object by **unique()** method. It returns categories in the order of appearance, \n","and it only includes values that are actually present."]},{"cell_type":"code","execution_count":46,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["array(['F', 'M'], dtype=object)"]},"execution_count":46,"metadata":{},"output_type":"execute_result"}],"source":["df3['Gender'].unique()"]},{"cell_type":"code","execution_count":47,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["array(['0-17', '55+', '26-35', '46-50', '51-55', '36-45', '18-25'],\n","      dtype=object)"]},"execution_count":47,"metadata":{},"output_type":"execute_result"}],"source":["df3['Age'].unique()"]},{"cell_type":"markdown","metadata":{},"source":["### Rename categories\n","\n","\n","Renaming categories is done by assigning new values to the `Series.cat.categories` property or by using the `rename_categories()` method.\n","\n","\n","\n","\n","### Append new categories\n","\n","\n","Appending categories can be done by using the `add_categories()` method.\n","\n","\n","\n","\n","### Remove categories\n","\n","\n","Removing categories can be done by using the `remove_categories()` method. Values which are removed are replaced by np.nan.\n","\n","\n","\n","\n","### Setting categories\n","\n","\n","If we want to remove and add new categories in one step (which has some speed advantage), or simply set the categories to a predefined scale, we can use `set_categories()` method.\n","\n","\n","\n","\n","### Reordering categories\n","\n","\n","Reordering the categories is possible via the `Categorical.reorder_categories()` and the `Categorical.set_categories()` methods. \n","\n","\n","\n","### Operations on categorical data \n","\n","\n","There are several operations like `Series.min()`, `Series.max()`, `Series.median()` and `Series.mode()` which are possible with categorical data. "]},{"cell_type":"markdown","metadata":{},"source":["### Frequency counts of categorical data\n","\n","\n","Series methods like `Series.value_counts()` will return the frequency counts of the categories present in the series."]},{"cell_type":"code","execution_count":48,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["M    414259\n","F    135809\n","Name: Gender, dtype: int64"]},"execution_count":48,"metadata":{},"output_type":"execute_result"}],"source":["df3['Gender'].value_counts()"]},{"cell_type":"code","execution_count":49,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["B    231173\n","C    171175\n","A    147720\n","Name: City_Category, dtype: int64"]},"execution_count":49,"metadata":{},"output_type":"execute_result"}],"source":["df3['City_Category'].value_counts()"]},{"cell_type":"markdown","metadata":{},"source":["`Series.value_counts()` will return the frequency counts of the categories in descending order. To get the categories in \n","ascending order we should set `ascending=True` as follows:-"]},{"cell_type":"code","execution_count":50,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["F    135809\n","M    414259\n","Name: Gender, dtype: int64"]},"execution_count":50,"metadata":{},"output_type":"execute_result"}],"source":["df3['Gender'].value_counts(ascending=True)"]},{"cell_type":"code","execution_count":51,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["A    147720\n","C    171175\n","B    231173\n","Name: City_Category, dtype: int64"]},"execution_count":51,"metadata":{},"output_type":"execute_result"}],"source":["df3['City_Category'].value_counts(ascending=True)"]},{"cell_type":"markdown","metadata":{},"source":["# 17. Basic functionality in pandas <a class=\"anchor\" id=\"17\"></a>\n","\n","\n","[Back to Table of Contents](#0.1)\n","\n","\n","\n","### Series basic functionality\n","\n","\n","\n","The following table lists the important attributes or methods in Series basic functionality.\n","\n","\n","\n","- **axes** - Returns a list of the row axis labels\n","\n","\n","- **dtype** - Returns the dtype of the object.\n","\n","\n","- **empty** - Returns True if series is empty.\n","\n","\n","- **ndim** - Returns the number of dimensions of the underlying data, by definition 1.\n","\n","\n","- **size** - Returns the number of elements in the underlying data.\n","\n","\n","- **values** - Returns the Series as ndarray.\n","\n","\n","- **head()** - Returns the first n rows.\n","\n","\n","- **tail()** - Returns the last n rows.\n","\n","\n","\n","\n","### Dataframe basic functionality\n","\n","\n","\n","The following tables lists the important attributes or methods in Dataframe basic functionality.\n","\n","\n","\n","- **T** - Transposes rows and columns.\n","\n","\n","- **axes** - Returns a list with the row axis labels and column axis labels as the only members.\n","\n","\n","- **dtypes** - Returns the dtypes in this object.\n","\n","\n","- **empty** -  True if NDFrame is entirely empty [no items]; if any of the axes are of length 0.\n","\n","\n","- **ndim** -  Number of axes / array dimensions.\n","\n","\n","- **shape** -  Returns a tuple representing the dimensionality of the Dataframe.\n","\n","\n","- **size** - Number of elements in the NDFrame.\n","\n","\n","- **values** - Numpy representation of NDFrame.\n","\n","\n","\n","- **head()** - Returns the first n rows.\n","\n","\n","- **tail()** - Returns last n rows."]},{"cell_type":"markdown","metadata":{},"source":["# 18. Descriptive statistics in pandas <a class=\"anchor\" id=\"18\"></a>\n","\n","\n","[Back to Table of Contents](#0.1)\n","\n","\n","\n","There exists a large number of methods for computing descriptive statistics and other related operations on Series, DataFrame, and Panel. Most of these are aggregations (hence producing a lower-dimensional result) like sum(), mean(), and quantile(), but some of them, like cumsum() and cumprod(), produce an object of the same size. Generally speaking, these methods take an axis argument, just like ndarray.{sum, std, …}, but the axis can be specified by name or integer.\n","\n","\n","- Series: no axis argument needed.\n","\n","\n","- DataFrame: “index” (axis=0, default), “columns” (axis=1).\n","\n","\n","- Panel: “items” (axis=0), “major” (axis=1, default), “minor” (axis=2).\n","\n","\n","\n","### Functions and description\n","\n","\n","The following table list down the important functions under Descriptive Statistics in Python Pandas. \n","\n","\n","\n","- 1   **count()** -\tNumber of non-null observations\n","\n","\n","- 2\t  **sum()**\t  - Sum of values\n","\n","\n","- 3\t  **mean()**  -\tMean of values\n","\n","\n","- 4\t **median()** -\tMedian of values\n","\n","\n","- 5\t **mode()**  -\tMode of values\n","\n","\n","- 6\t **std()**   -\tStandard deviation of the values\n","\n","\n","- 7\t **min()**   -\tMinimum value\n","\n","\n","- 8\t **max()**   -\tMaximum value\n","\n","\n","- 9\t **abs()**   -\tAbsolute value\n","\n","\n","- 10 **prod()**  -\tProduct of values\n","\n","\n","- 11 **cumsum()** -\tCumulative sum\n","\n","\n","- 12 **cumprod()** - Cumulative product\n","\n","\n","\n","The dataframe is a heterogeneous data structure. So, the different column values have different data types. Generic operations don't work with all functions.\n","\n","\n","Functions like **sum()**, **cumsum()** work with both numeric and character (or) string data elements without any error. \n","In practice, character aggregations are never used generally. These functions do not throw any exception.\n","\n","\n","Functions like **abs()**, **cumprod()** throw exception when the dataframe contains character or string data because such operations cannot be performed.\n"]},{"cell_type":"code","execution_count":52,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["User_ID                        1006040\n","Product_ID                    P0099942\n","Gender                               M\n","Age                                55+\n","Occupation                          20\n","City_Category                        C\n","Stay_In_Current_City_Years          4+\n","Marital_Status                       1\n","Product_Category_1                  20\n","Product_Category_2                  18\n","Product_Category_3                  18\n","Purchase                         23961\n","dtype: object"]},"execution_count":52,"metadata":{},"output_type":"execute_result"}],"source":["df4=df.copy()\n","\n","df4.max(0)"]},{"cell_type":"markdown","metadata":{},"source":["### Summarizing data\n","\n","\n","\n","The **describe()** function computes the summary statistics of the numerical columns in the dataframe.\n","\n","\n","\n","This function gives the mean, std and IQR values. It excludes the character columns and gives summary about numeric columns. \n","It includes the argument which is used to pass necessary information regarding what columns need to be considered for summarizing. It takes the list of values; by default, 'number'.\n","\n","\n","- object − Summarizes string columns\n","\n","\n","- number − Summarizes numeric columns\n","\n","\n","- all − Summarizes all columns together"]},{"cell_type":"code","execution_count":53,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>User_ID</th>\n","      <th>Occupation</th>\n","      <th>Marital_Status</th>\n","      <th>Product_Category_1</th>\n","      <th>Product_Category_2</th>\n","      <th>Product_Category_3</th>\n","      <th>Purchase</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>5.500680e+05</td>\n","      <td>550068.000000</td>\n","      <td>550068.000000</td>\n","      <td>550068.000000</td>\n","      <td>550068.000000</td>\n","      <td>550068.000000</td>\n","      <td>550068.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>1.003029e+06</td>\n","      <td>8.076707</td>\n","      <td>0.409653</td>\n","      <td>5.404270</td>\n","      <td>9.863190</td>\n","      <td>12.650723</td>\n","      <td>9263.968713</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>1.727592e+03</td>\n","      <td>6.522660</td>\n","      <td>0.491770</td>\n","      <td>3.936211</td>\n","      <td>5.049456</td>\n","      <td>4.115118</td>\n","      <td>5023.065394</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>1.000001e+06</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>2.000000</td>\n","      <td>3.000000</td>\n","      <td>12.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>1.001516e+06</td>\n","      <td>2.000000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>5.000000</td>\n","      <td>9.000000</td>\n","      <td>5823.000000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>1.003077e+06</td>\n","      <td>7.000000</td>\n","      <td>0.000000</td>\n","      <td>5.000000</td>\n","      <td>9.000000</td>\n","      <td>14.000000</td>\n","      <td>8047.000000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>1.004478e+06</td>\n","      <td>14.000000</td>\n","      <td>1.000000</td>\n","      <td>8.000000</td>\n","      <td>15.000000</td>\n","      <td>16.000000</td>\n","      <td>12054.000000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>1.006040e+06</td>\n","      <td>20.000000</td>\n","      <td>1.000000</td>\n","      <td>20.000000</td>\n","      <td>18.000000</td>\n","      <td>18.000000</td>\n","      <td>23961.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["            User_ID     Occupation  Marital_Status  Product_Category_1  \\\n","count  5.500680e+05  550068.000000   550068.000000       550068.000000   \n","mean   1.003029e+06       8.076707        0.409653            5.404270   \n","std    1.727592e+03       6.522660        0.491770            3.936211   \n","min    1.000001e+06       0.000000        0.000000            1.000000   \n","25%    1.001516e+06       2.000000        0.000000            1.000000   \n","50%    1.003077e+06       7.000000        0.000000            5.000000   \n","75%    1.004478e+06      14.000000        1.000000            8.000000   \n","max    1.006040e+06      20.000000        1.000000           20.000000   \n","\n","       Product_Category_2  Product_Category_3       Purchase  \n","count       550068.000000       550068.000000  550068.000000  \n","mean             9.863190           12.650723    9263.968713  \n","std              5.049456            4.115118    5023.065394  \n","min              2.000000            3.000000      12.000000  \n","25%              5.000000            9.000000    5823.000000  \n","50%              9.000000           14.000000    8047.000000  \n","75%             15.000000           16.000000   12054.000000  \n","max             18.000000           18.000000   23961.000000  "]},"execution_count":53,"metadata":{},"output_type":"execute_result"}],"source":["df4.describe()"]},{"cell_type":"markdown","metadata":{},"source":["# 19. Statistical functions in pandas <a class=\"anchor\" id=\"19\"></a>\n","\n","\n","[Back to Table of Contents](#0.1)\n","\n","\n","\n","Statistical functions help us to understand and analyze the behavior of data. In this section, I will discuss few statistical functions, which we can apply on Pandas objects.\n","\n","\n","\n","### Percent_change\n","\n","\n","Series, datFrames and panel, all have the function **pct_change()**. This function compares every element with its prior element and computes the change percentage.\n","\n","By default, the pct_change() operates on columns; if you want to apply the same row wise, then use axis=1() argument.\n","\n","\n","\n","### Covariance\n","\n","\n","Covariance is applied on series data. The series object has a method **cov()** to compute covariance between series objects. NA values will be excluded automatically.\n","\n","\n","**Series.cov()** can be used to compute covariance between series (excluding missing values).\n","\n","\n","Analogously, **dataFrame.cov()** to compute pairwise covariances among the series in the dataFrame, also excluding NA/null values.\n"]},{"cell_type":"code","execution_count":54,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>User_ID</th>\n","      <th>Occupation</th>\n","      <th>Marital_Status</th>\n","      <th>Product_Category_1</th>\n","      <th>Product_Category_2</th>\n","      <th>Product_Category_3</th>\n","      <th>Purchase</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>User_ID</th>\n","      <td>2.984573e+06</td>\n","      <td>-270.113921</td>\n","      <td>17.367619</td>\n","      <td>26.008008</td>\n","      <td>14.424454</td>\n","      <td>8.800208</td>\n","      <td>4.092159e+04</td>\n","    </tr>\n","    <tr>\n","      <th>Occupation</th>\n","      <td>-2.701139e+02</td>\n","      <td>42.545100</td>\n","      <td>0.077882</td>\n","      <td>-0.195578</td>\n","      <td>-0.032437</td>\n","      <td>0.102383</td>\n","      <td>6.825547e+02</td>\n","    </tr>\n","    <tr>\n","      <th>Marital_Status</th>\n","      <td>1.736762e+01</td>\n","      <td>0.077882</td>\n","      <td>0.241838</td>\n","      <td>0.038497</td>\n","      <td>0.036533</td>\n","      <td>0.024521</td>\n","      <td>-1.144629e+00</td>\n","    </tr>\n","    <tr>\n","      <th>Product_Category_1</th>\n","      <td>2.600801e+01</td>\n","      <td>-0.195578</td>\n","      <td>0.038497</td>\n","      <td>15.493760</td>\n","      <td>5.921467</td>\n","      <td>0.800453</td>\n","      <td>-6.795650e+03</td>\n","    </tr>\n","    <tr>\n","      <th>Product_Category_2</th>\n","      <td>1.442445e+01</td>\n","      <td>-0.032437</td>\n","      <td>0.036533</td>\n","      <td>5.921467</td>\n","      <td>25.497002</td>\n","      <td>4.887472</td>\n","      <td>-3.330587e+03</td>\n","    </tr>\n","    <tr>\n","      <th>Product_Category_3</th>\n","      <td>8.800208e+00</td>\n","      <td>0.102383</td>\n","      <td>0.024521</td>\n","      <td>0.800453</td>\n","      <td>4.887472</td>\n","      <td>16.934197</td>\n","      <td>1.780200e+02</td>\n","    </tr>\n","    <tr>\n","      <th>Purchase</th>\n","      <td>4.092159e+04</td>\n","      <td>682.554656</td>\n","      <td>-1.144629</td>\n","      <td>-6795.650007</td>\n","      <td>-3330.586593</td>\n","      <td>178.020034</td>\n","      <td>2.523119e+07</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                         User_ID  Occupation  Marital_Status  \\\n","User_ID             2.984573e+06 -270.113921       17.367619   \n","Occupation         -2.701139e+02   42.545100        0.077882   \n","Marital_Status      1.736762e+01    0.077882        0.241838   \n","Product_Category_1  2.600801e+01   -0.195578        0.038497   \n","Product_Category_2  1.442445e+01   -0.032437        0.036533   \n","Product_Category_3  8.800208e+00    0.102383        0.024521   \n","Purchase            4.092159e+04  682.554656       -1.144629   \n","\n","                    Product_Category_1  Product_Category_2  \\\n","User_ID                      26.008008           14.424454   \n","Occupation                   -0.195578           -0.032437   \n","Marital_Status                0.038497            0.036533   \n","Product_Category_1           15.493760            5.921467   \n","Product_Category_2            5.921467           25.497002   \n","Product_Category_3            0.800453            4.887472   \n","Purchase                  -6795.650007        -3330.586593   \n","\n","                    Product_Category_3      Purchase  \n","User_ID                       8.800208  4.092159e+04  \n","Occupation                    0.102383  6.825547e+02  \n","Marital_Status                0.024521 -1.144629e+00  \n","Product_Category_1            0.800453 -6.795650e+03  \n","Product_Category_2            4.887472 -3.330587e+03  \n","Product_Category_3           16.934197  1.780200e+02  \n","Purchase                    178.020034  2.523119e+07  "]},"execution_count":54,"metadata":{},"output_type":"execute_result"}],"source":["df5=df.copy()\n","\n","\n","# view the covariance\n","\n","df5.cov()"]},{"cell_type":"markdown","metadata":{},"source":["### Correlation\n","\n","\n","**Correlation** shows the linear relationship between any two array of values (series). There are multiple methods to compute the correlation. These methods are listed below:-\n","\n","\n","\n","**Method name**  \t  **Description**\n","\n","\n","- pearson (default)\t-  Standard correlation coefficient\n","\n","\n","- kendall           -  Kendall Tau correlation coefficient\n","\n","\n","- spearman\t        -  Spearman rank correlation coefficient\n","\n","\n","\n","All of these are currently computed using pairwise complete observations.\n","\n","\n","Any non-numeric columns will be automatically excluded from the correlation calculation."]},{"cell_type":"code","execution_count":55,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>User_ID</th>\n","      <th>Occupation</th>\n","      <th>Marital_Status</th>\n","      <th>Product_Category_1</th>\n","      <th>Product_Category_2</th>\n","      <th>Product_Category_3</th>\n","      <th>Purchase</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>User_ID</th>\n","      <td>1.000000</td>\n","      <td>-0.023971</td>\n","      <td>0.020443</td>\n","      <td>0.003825</td>\n","      <td>0.001654</td>\n","      <td>0.001238</td>\n","      <td>0.004716</td>\n","    </tr>\n","    <tr>\n","      <th>Occupation</th>\n","      <td>-0.023971</td>\n","      <td>1.000000</td>\n","      <td>0.024280</td>\n","      <td>-0.007618</td>\n","      <td>-0.000985</td>\n","      <td>0.003814</td>\n","      <td>0.020833</td>\n","    </tr>\n","    <tr>\n","      <th>Marital_Status</th>\n","      <td>0.020443</td>\n","      <td>0.024280</td>\n","      <td>1.000000</td>\n","      <td>0.019888</td>\n","      <td>0.014712</td>\n","      <td>0.012117</td>\n","      <td>-0.000463</td>\n","    </tr>\n","    <tr>\n","      <th>Product_Category_1</th>\n","      <td>0.003825</td>\n","      <td>-0.007618</td>\n","      <td>0.019888</td>\n","      <td>1.000000</td>\n","      <td>0.297925</td>\n","      <td>0.049417</td>\n","      <td>-0.343703</td>\n","    </tr>\n","    <tr>\n","      <th>Product_Category_2</th>\n","      <td>0.001654</td>\n","      <td>-0.000985</td>\n","      <td>0.014712</td>\n","      <td>0.297925</td>\n","      <td>1.000000</td>\n","      <td>0.235211</td>\n","      <td>-0.131313</td>\n","    </tr>\n","    <tr>\n","      <th>Product_Category_3</th>\n","      <td>0.001238</td>\n","      <td>0.003814</td>\n","      <td>0.012117</td>\n","      <td>0.049417</td>\n","      <td>0.235211</td>\n","      <td>1.000000</td>\n","      <td>0.008612</td>\n","    </tr>\n","    <tr>\n","      <th>Purchase</th>\n","      <td>0.004716</td>\n","      <td>0.020833</td>\n","      <td>-0.000463</td>\n","      <td>-0.343703</td>\n","      <td>-0.131313</td>\n","      <td>0.008612</td>\n","      <td>1.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                     User_ID  Occupation  Marital_Status  Product_Category_1  \\\n","User_ID             1.000000   -0.023971        0.020443            0.003825   \n","Occupation         -0.023971    1.000000        0.024280           -0.007618   \n","Marital_Status      0.020443    0.024280        1.000000            0.019888   \n","Product_Category_1  0.003825   -0.007618        0.019888            1.000000   \n","Product_Category_2  0.001654   -0.000985        0.014712            0.297925   \n","Product_Category_3  0.001238    0.003814        0.012117            0.049417   \n","Purchase            0.004716    0.020833       -0.000463           -0.343703   \n","\n","                    Product_Category_2  Product_Category_3  Purchase  \n","User_ID                       0.001654            0.001238  0.004716  \n","Occupation                   -0.000985            0.003814  0.020833  \n","Marital_Status                0.014712            0.012117 -0.000463  \n","Product_Category_1            0.297925            0.049417 -0.343703  \n","Product_Category_2            1.000000            0.235211 -0.131313  \n","Product_Category_3            0.235211            1.000000  0.008612  \n","Purchase                     -0.131313            0.008612  1.000000  "]},"execution_count":55,"metadata":{},"output_type":"execute_result"}],"source":["# view the correlation\n","\n","df5.corr()"]},{"cell_type":"markdown","metadata":{},"source":["### Data Ranking\n","\n","\n","Data Ranking produces ranking for each element in the array of elements. In case of ties, assigns the mean rank. \n","\n","\n","The **rank()** method produces a data ranking with ties being assigned the mean of the ranks (by default) for the group.\n","\n","\n","The **rank()** is also a dataframe method and can rank either the rows (axis=0) or the columns (axis=1). NaN values are excluded from the ranking.\n","\n","\n","It optionally takes a parameter ascending which true by default. If it is set to false, data is ranked in descending order, with larger values assigned a smaller rank.\n","\n","\n","The **rank()** supports different tie-breaking methods, specified with the method parameter as follows:-\n","\n","\n","- **average** - average rank of tied group\n","\n","\n","- **min** - lowest rank in the group\n","\n","\n","- **max** - highest rank in the group\n","\n","\n","- **first** - ranks assigned in the order they appear in the array"]},{"cell_type":"code","execution_count":56,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>User_ID</th>\n","      <th>Occupation</th>\n","      <th>Marital_Status</th>\n","      <th>Product_Category_1</th>\n","      <th>Product_Category_2</th>\n","      <th>Product_Category_3</th>\n","      <th>Purchase</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>7.0</td>\n","      <td>4.0</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>3.0</td>\n","      <td>5.0</td>\n","      <td>6.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>7.0</td>\n","      <td>4.0</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>3.0</td>\n","      <td>5.0</td>\n","      <td>6.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>7.0</td>\n","      <td>3.0</td>\n","      <td>1.0</td>\n","      <td>4.0</td>\n","      <td>2.0</td>\n","      <td>5.0</td>\n","      <td>6.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>7.0</td>\n","      <td>2.0</td>\n","      <td>1.0</td>\n","      <td>3.0</td>\n","      <td>4.5</td>\n","      <td>4.5</td>\n","      <td>6.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>7.0</td>\n","      <td>5.0</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>3.5</td>\n","      <td>3.5</td>\n","      <td>6.0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>7.0</td>\n","      <td>5.0</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>3.0</td>\n","      <td>4.0</td>\n","      <td>6.0</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>7.0</td>\n","      <td>3.0</td>\n","      <td>1.5</td>\n","      <td>1.5</td>\n","      <td>4.0</td>\n","      <td>5.0</td>\n","      <td>6.0</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>7.0</td>\n","      <td>3.0</td>\n","      <td>1.5</td>\n","      <td>1.5</td>\n","      <td>4.0</td>\n","      <td>5.0</td>\n","      <td>6.0</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>7.0</td>\n","      <td>3.0</td>\n","      <td>1.5</td>\n","      <td>1.5</td>\n","      <td>4.0</td>\n","      <td>5.0</td>\n","      <td>6.0</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>7.0</td>\n","      <td>5.0</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>3.0</td>\n","      <td>4.0</td>\n","      <td>6.0</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>7.0</td>\n","      <td>5.0</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>3.0</td>\n","      <td>4.0</td>\n","      <td>6.0</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>7.0</td>\n","      <td>5.0</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>3.0</td>\n","      <td>4.0</td>\n","      <td>6.0</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>7.0</td>\n","      <td>5.0</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>3.0</td>\n","      <td>4.0</td>\n","      <td>6.0</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>7.0</td>\n","      <td>5.0</td>\n","      <td>1.5</td>\n","      <td>1.5</td>\n","      <td>3.0</td>\n","      <td>4.0</td>\n","      <td>6.0</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>7.0</td>\n","      <td>4.0</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>3.0</td>\n","      <td>5.0</td>\n","      <td>6.0</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>7.0</td>\n","      <td>4.0</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>3.0</td>\n","      <td>5.0</td>\n","      <td>6.0</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>7.0</td>\n","      <td>5.0</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>3.0</td>\n","      <td>4.0</td>\n","      <td>6.0</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>7.0</td>\n","      <td>4.0</td>\n","      <td>1.0</td>\n","      <td>3.0</td>\n","      <td>5.0</td>\n","      <td>2.0</td>\n","      <td>6.0</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>7.0</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>4.0</td>\n","      <td>5.0</td>\n","      <td>6.0</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>7.0</td>\n","      <td>4.0</td>\n","      <td>1.5</td>\n","      <td>1.5</td>\n","      <td>3.0</td>\n","      <td>5.0</td>\n","      <td>6.0</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>7.0</td>\n","      <td>3.0</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>4.0</td>\n","      <td>5.0</td>\n","      <td>6.0</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>7.0</td>\n","      <td>3.0</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>4.0</td>\n","      <td>5.0</td>\n","      <td>6.0</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>7.0</td>\n","      <td>3.0</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>4.0</td>\n","      <td>5.0</td>\n","      <td>6.0</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>7.0</td>\n","      <td>3.0</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>4.0</td>\n","      <td>5.0</td>\n","      <td>6.0</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>7.0</td>\n","      <td>4.0</td>\n","      <td>1.5</td>\n","      <td>1.5</td>\n","      <td>3.0</td>\n","      <td>5.0</td>\n","      <td>6.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    User_ID  Occupation  Marital_Status  Product_Category_1  \\\n","0       7.0         4.0             1.0                 2.0   \n","1       7.0         4.0             1.0                 2.0   \n","2       7.0         3.0             1.0                 4.0   \n","3       7.0         2.0             1.0                 3.0   \n","4       7.0         5.0             1.0                 2.0   \n","5       7.0         5.0             1.0                 2.0   \n","6       7.0         3.0             1.5                 1.5   \n","7       7.0         3.0             1.5                 1.5   \n","8       7.0         3.0             1.5                 1.5   \n","9       7.0         5.0             1.0                 2.0   \n","10      7.0         5.0             1.0                 2.0   \n","11      7.0         5.0             1.0                 2.0   \n","12      7.0         5.0             1.0                 2.0   \n","13      7.0         5.0             1.5                 1.5   \n","14      7.0         4.0             1.0                 2.0   \n","15      7.0         4.0             1.0                 2.0   \n","16      7.0         5.0             1.0                 2.0   \n","17      7.0         4.0             1.0                 3.0   \n","18      7.0         2.0             2.0                 2.0   \n","19      7.0         4.0             1.5                 1.5   \n","20      7.0         3.0             1.0                 2.0   \n","21      7.0         3.0             1.0                 2.0   \n","22      7.0         3.0             1.0                 2.0   \n","23      7.0         3.0             1.0                 2.0   \n","24      7.0         4.0             1.5                 1.5   \n","\n","    Product_Category_2  Product_Category_3  Purchase  \n","0                  3.0                 5.0       6.0  \n","1                  3.0                 5.0       6.0  \n","2                  2.0                 5.0       6.0  \n","3                  4.5                 4.5       6.0  \n","4                  3.5                 3.5       6.0  \n","5                  3.0                 4.0       6.0  \n","6                  4.0                 5.0       6.0  \n","7                  4.0                 5.0       6.0  \n","8                  4.0                 5.0       6.0  \n","9                  3.0                 4.0       6.0  \n","10                 3.0                 4.0       6.0  \n","11                 3.0                 4.0       6.0  \n","12                 3.0                 4.0       6.0  \n","13                 3.0                 4.0       6.0  \n","14                 3.0                 5.0       6.0  \n","15                 3.0                 5.0       6.0  \n","16                 3.0                 4.0       6.0  \n","17                 5.0                 2.0       6.0  \n","18                 4.0                 5.0       6.0  \n","19                 3.0                 5.0       6.0  \n","20                 4.0                 5.0       6.0  \n","21                 4.0                 5.0       6.0  \n","22                 4.0                 5.0       6.0  \n","23                 4.0                 5.0       6.0  \n","24                 3.0                 5.0       6.0  "]},"execution_count":56,"metadata":{},"output_type":"execute_result"}],"source":["# view the top 25 rows of ranked dataframe\n","\n","df5.rank(1).head(25)"]},{"cell_type":"markdown","metadata":{},"source":["### Common statistical functions\n","\n","\n","There are a number of common statistical functions. These are listed below:-\n","\n","\n","\n","**Method**    -  **Description**\n","\n","\n","- **count()** - Number of non-null observations\n","\n","\n","- **sum()** -   Sum of values\n","\n","\n","- **mean()** -  Mean of values\n","\n","\n","- **median()** - Arithmetic median of values\n","\n","\n","- **min()** -\tMinimum\n","\n","\n","- **max()** - \tMaximum\n","\n","\n","- **std()** -\tStandard deviation\n","\n","\n","- **var()** -\tVariance\n","\n","\n","- **skew()** -\tSkewness\n","\n","\n","- **kurt()** -\tKurtosis\n","\n","\n","- **quantile()** -\tQuantile\n","\n","\n","- **apply()** -\tGeneric apply\n","\n","\n","- **cov()** -\tCovariance\n","\n","\n","- **corr()** -\tCorrelation\n","\n","\n","\n","The **apply()** function takes an extra **func** argument and performs generic rolling computations. The **func** argument should be a single function that produces a single value from an ndarray input."]},{"cell_type":"markdown","metadata":{},"source":["# 20. Window functions in pandas <a class=\"anchor\" id=\"20\"></a>\n","\n","\n","[Back to Table of Contents](#0.1)\n","\n","\n","For working with numerical data, Pandas provide few variants like **rolling**, **expanding** and **exponentially moving weights** for window statistics. \n","\n","\n","Among these are **count**, **sum**, **mean**, **median**, **correlation**, **variance**, **covariance**, **standard deviation**, **skewness** and **kurtosis**.\n","\n","\n","The **rolling()** and **expanding()** functions can be used directly from DataFrameGroupBy objects.\n","\n","\n","In this section, we work with rolling, expanding and exponentially weighted data through the corresponding objects, **Rolling**, **Expanding** and **EWM**."]},{"cell_type":"markdown","metadata":{},"source":["### rolling() function\n","\n","\n","This function can be applied on a series of data. Specify the **window=n** argument and apply the appropriate statistical function on top of it.\n","\n","\n","`df6=df.copy()`\n","\n","\n","`df6.rolling(window=3).mean()`\n","\n","\n","Since the window size is 3, for first two elements there are nulls and from third the value will be the average of the n, n-1 and n-2 elements. We can also apply various functions.\n","\n","\n","\n","### expanding() function\n","\n","\n","This function can be applied on a series of data. We specify the **min_periods=n** argument and apply the appropriate statistical function on top of it.\n","\n","\n","`df6.expanding(min_periods=3).mean()`\n","\n","\n","\n","\n","### ewm() function\n","\n","\n","**ewm** is applied on a series of data. We have to specify any of the com, span, halflife argument and apply the appropriate statistical function on top of it. It assigns the weights exponentially.\n","\n","\n","`df6.ewm(com=0.5).mean()`\n","\n","\n","\n","Window functions are used in finding the trends within the data graphically by smoothing the curve. If there is a lot of variation in the data, then we can apply window functions to smooth out the curve or the trend.\n"]},{"cell_type":"markdown","metadata":{},"source":["# 21. Aggregations in pandas <a class=\"anchor\" id=\"21\"></a>\n","\n","\n","[Back to Table of Contents](#0.1)\n","\n","\n","Once the rolling, expanding and ewm objects are created, several methods are available to perform aggregations on data.\n","\n","\n","### Apply aggregation on a whole dataframe\n","\n","\n","`df6=df.copy`\n","\n","\n","`df6.aggregate(np.sum)`\n","\n","\n","\n","### Apply aggregation on a single column of a dataframe\n"]},{"cell_type":"code","execution_count":57,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["5095812742"]},"execution_count":57,"metadata":{},"output_type":"execute_result"}],"source":["df6=df.copy()\n","\n","\n","df6['Purchase'].aggregate(np.sum)"]},{"cell_type":"markdown","metadata":{},"source":["### Apply multiple functions on a single column of a dataframe"]},{"cell_type":"code","execution_count":58,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["sum     5.095813e+09\n","mean    9.263969e+03\n","Name: Purchase, dtype: float64"]},"execution_count":58,"metadata":{},"output_type":"execute_result"}],"source":["df6['Purchase'].aggregate([np.sum, np.mean])"]},{"cell_type":"markdown","metadata":{},"source":["### Apply aggregation on multiple columns of a dataframe"]},{"cell_type":"code","execution_count":59,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["Product_Category_1     5.404270\n","Product_Category_2     9.863190\n","Product_Category_3    12.650723\n","dtype: float64"]},"execution_count":59,"metadata":{},"output_type":"execute_result"}],"source":["df6[['Product_Category_1', 'Product_Category_2', 'Product_Category_3']].aggregate(np.mean)"]},{"cell_type":"markdown","metadata":{},"source":["### Apply multiple functions on multiple columns of a dataframe"]},{"cell_type":"code","execution_count":60,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Product_Category_1</th>\n","      <th>Product_Category_2</th>\n","      <th>Product_Category_3</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>sum</th>\n","      <td>2.972716e+06</td>\n","      <td>5.425425e+06</td>\n","      <td>6.958758e+06</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>5.404270e+00</td>\n","      <td>9.863190e+00</td>\n","      <td>1.265072e+01</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      Product_Category_1  Product_Category_2  Product_Category_3\n","sum         2.972716e+06        5.425425e+06        6.958758e+06\n","mean        5.404270e+00        9.863190e+00        1.265072e+01"]},"execution_count":60,"metadata":{},"output_type":"execute_result"}],"source":["df6[['Product_Category_1', 'Product_Category_2', 'Product_Category_3']].aggregate([np.sum, np.mean])"]},{"cell_type":"markdown","metadata":{},"source":["### Apply different functions to different columns of a dataframe"]},{"cell_type":"code","execution_count":61,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["Product_Category_1    2.972716e+06\n","Product_Category_2    9.863190e+00\n","dtype: float64"]},"execution_count":61,"metadata":{},"output_type":"execute_result"}],"source":["df6.aggregate({'Product_Category_1' : np.sum ,'Product_Category_2' : np.mean})"]},{"cell_type":"markdown","metadata":{},"source":["# 22. Iteration in pandas <a class=\"anchor\" id=\"22\"></a>\n","\n","\n","[Back to Table of Contents](#0.1)\n","\n","\n","\n","The behavior of basic iteration over Pandas objects depends on the type. When iterating over a Series, it is regarded as \n","array-like, and basic iteration produces the values. Other data structures, like DataFrame and Panel, follow the **dict-like** convention of iterating over the **keys** of the objects.\n","\n","\n","\n","Iterating a dataframe gives column names.\n","\n","\n","\n","To iterate over the rows of the DataFrame, we can use the following functions −\n","\n","\n","\n","- **iteritems()** − to iterate over the (key,value) pairs\n","\n","\n","- **iterrows()** − iterate over the rows as (index,series) pairs\n","\n","\n","- **itertuples()** − iterate over the rows as namedtuples"]},{"cell_type":"markdown","metadata":{},"source":["# 23. Function application in pandas <a class=\"anchor\" id=\"23\"></a>\n","\n","\n","[Back to Table of Contents](#0.1)\n","\n","\n","\n","There are three important methods that enable us to apply our own or another library's functions to pandas objects. These methods differentiate on their scope of usage. These functions expect to operate on an entire dataframe, row- or column-wise\n","operation, or element wise operation. These methods are described below:-\n","\n","\n","- Table wise Function Application: **pipe()**\n","\n","\n","\n","- Row or Column Wise Function Application: **apply()**\n","\n","\n","\n","- Element wise Function Application: **applymap()**\n"]},{"cell_type":"markdown","metadata":{},"source":["### Table-wise Function Application:pipe()\n","\n","\n","Custom operations can be performed by passing the function and the appropriate number of parameters as pipe arguments. Thus, operation is performed on the whole DataFrame.\n","\n","\n","For example, if we want to add a value 10 to all the elements in the DataFrame. Then, we can make use of **pipe()** function \n","as follows:-\n","\n","\n","`def addten(x1,x2):`\n","\n","\n","    `return x1+x2`\n","   \n","\n","`df7=df.copy()` \n","\n","\n","`df7.pipe(addten,10)`"]},{"cell_type":"markdown","metadata":{},"source":["### Row or Column Wise Function Application: apply()\n","\n","\n","Arbitrary functions can be applied along the axes of a DataFrame or Panel using the **apply()** method. It takes an optional axis argument. By default, the operation performs column wise, taking each column as an array-like.\n","\n","\n","`df7.apply(np.mean)`\n","\n","\n","By passing axis parameter, operations can be performed row wise.\n","\n","\n","`df7.apply(np.mean,axis=1)`\n","\n","\n","`df.apply(lambda x: x.max() - x.min())`"]},{"cell_type":"markdown","metadata":{},"source":["### Element Wise Function Application: applymap()\n","\n","\n","\n","The methods **applymap()** on dataframe and analogously **map()** on series accept any Python function. It takes a single value and returns a single value.\n","\n","\n","`df7.applymap(lambda x:x*100)`\n"]},{"cell_type":"markdown","metadata":{},"source":["# 24. Pandas GroupBy operations <a class=\"anchor\" id=\"24\"></a>\n","\n","\n","[Back to Table of Contents](#0.1)\n","\n","\n","A groupby operation involves one of the following operations on the original object. They are as follows :−\n","\n","\n","- **Splitting** the Object\n","\n","\n","- **Applying** a function\n","\n","\n","- **Combining** the results\n","\n","\n","\n","The split step is the most straightforward out of these. In many situations, we may wish to split the data set into groups \n","and perform operations on those groups.\n","\n","\n","In the apply functionality, we can perform the following operations :−\n","\n","\n","\n","- **Aggregation** − compute a summary statistic (or statistics) for each group. Some examples are :- \n","\n","     - Compute group sums or means.                  \n","                  \n","     - Compute group sizes / counts.\n","\n","\n","\n","- **Transformation** − perform some group-specific computations and return a like-indexed object. Some examples are :-\n","\n","    - Standardize data (zscore) within a group.\n","    \n","    - Filling NAs within groups with a value derived from each group.\n","\n","\n","\n","- **Filtration** − discarding the data with some condition.  Some examples are :-\n","\n","    - Discard data that belongs to groups with only a few members.\n","    \n","    - Filter out data based on the group sum or mean.\n","    \n","    \n","    \n","- Some combination of the above: **GroupBy** will examine the results of the apply step and try to return a sensibly combined result if it doesn't fit into either of the above two categories."]},{"cell_type":"markdown","metadata":{},"source":["### Split Data into Groups\n","\n","\n","Pandas object can be split into any of their objects. There are multiple ways to split an object as follows :-\n","\n","\n","- obj.groupby('key')\n","\n","\n","- obj.groupby(['key1','key2'])\n","\n","\n","- obj.groupby(key,axis=1)\n","\n","\n","The following example illustrates the idea:-"]},{"cell_type":"code","execution_count":62,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["<pandas.core.groupby.generic.DataFrameGroupBy object at 0x7fadd4223a90>"]},"execution_count":62,"metadata":{},"output_type":"execute_result"}],"source":["df8=df.copy()\n","\n","df8.groupby('Gender')"]},{"cell_type":"code","execution_count":63,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["{'F': Int64Index([     0,      1,      2,      3,     14,     15,     16,     17,\n","                 29,     30,\n","             ...\n","             550046, 550047, 550051, 550053, 550059, 550061, 550064, 550065,\n","             550066, 550067],\n","            dtype='int64', length=135809),\n"," 'M': Int64Index([     4,      5,      6,      7,      8,      9,     10,     11,\n","                 12,     13,\n","             ...\n","             550050, 550052, 550054, 550055, 550056, 550057, 550058, 550060,\n","             550062, 550063],\n","            dtype='int64', length=414259)}"]},"execution_count":63,"metadata":{},"output_type":"execute_result"}],"source":["# view groups of Gender column\n","\n","df8.groupby('Gender').groups"]},{"cell_type":"markdown","metadata":{},"source":["### Group by with multiple columns\n","\n","\n","`df8.groupby(['Gender', 'Age']).groups`\n","\n","\n","\n","\n","### Iterate through groups\n","\n","\n","With the groupby object in hand, we can iterate through the object similar to itertools.obj.\n","\n","\n","`df8_grouped = df8.groupby('Gender')`\n","\n","\n","`for Age, Occupation in df8_grouped:`\n","\n","   `print Age`\n","   \n","   `print Occupation`\n","   \n","   \n","   \n","   \n","   \n","### Select a group with get_group() method\n","\n","\n","Using the **get_group()** method, we can select a single group.\n","\n","\n","`df8_grouped = df8.groupby('City_Category')`\n","\n","\n","`print(df8_grouped.get_group('A')`"]},{"cell_type":"markdown","metadata":{},"source":["### Aggregation functions with groupby\n","\n","\n","An aggregation function returns a single aggregated value for each group. Once the group by object is created, several aggregation operations can be performed on the grouped data as follows:-"]},{"cell_type":"code","execution_count":64,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>User_ID</th>\n","      <th>Occupation</th>\n","      <th>Marital_Status</th>\n","      <th>Product_Category_1</th>\n","      <th>Product_Category_2</th>\n","      <th>Product_Category_3</th>\n","      <th>Purchase</th>\n","    </tr>\n","    <tr>\n","      <th>Gender</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>F</th>\n","      <td>136234060927</td>\n","      <td>915426</td>\n","      <td>56988</td>\n","      <td>776517</td>\n","      <td>1356094.0</td>\n","      <td>1701913.0</td>\n","      <td>1186232642</td>\n","    </tr>\n","    <tr>\n","      <th>M</th>\n","      <td>415500008355</td>\n","      <td>3527312</td>\n","      <td>168349</td>\n","      <td>2196199</td>\n","      <td>4069331.0</td>\n","      <td>5256845.0</td>\n","      <td>3909580100</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["             User_ID  Occupation  Marital_Status  Product_Category_1  \\\n","Gender                                                                 \n","F       136234060927      915426           56988              776517   \n","M       415500008355     3527312          168349             2196199   \n","\n","        Product_Category_2  Product_Category_3    Purchase  \n","Gender                                                      \n","F                1356094.0           1701913.0  1186232642  \n","M                4069331.0           5256845.0  3909580100  "]},"execution_count":64,"metadata":{},"output_type":"execute_result"}],"source":["# apply aggregation function sum with groupby\n","\n","df8.groupby('Gender').sum()"]},{"cell_type":"code","execution_count":65,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>User_ID</th>\n","      <th>Occupation</th>\n","      <th>Marital_Status</th>\n","      <th>Product_Category_1</th>\n","      <th>Product_Category_2</th>\n","      <th>Product_Category_3</th>\n","      <th>Purchase</th>\n","    </tr>\n","    <tr>\n","      <th>Gender</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>F</th>\n","      <td>136234060927</td>\n","      <td>915426</td>\n","      <td>56988</td>\n","      <td>776517</td>\n","      <td>1356094.0</td>\n","      <td>1701913.0</td>\n","      <td>1186232642</td>\n","    </tr>\n","    <tr>\n","      <th>M</th>\n","      <td>415500008355</td>\n","      <td>3527312</td>\n","      <td>168349</td>\n","      <td>2196199</td>\n","      <td>4069331.0</td>\n","      <td>5256845.0</td>\n","      <td>3909580100</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["             User_ID  Occupation  Marital_Status  Product_Category_1  \\\n","Gender                                                                 \n","F       136234060927      915426           56988              776517   \n","M       415500008355     3527312          168349             2196199   \n","\n","        Product_Category_2  Product_Category_3    Purchase  \n","Gender                                                      \n","F                1356094.0           1701913.0  1186232642  \n","M                4069331.0           5256845.0  3909580100  "]},"execution_count":65,"metadata":{},"output_type":"execute_result"}],"source":["# alternative way to apply aggregation function sum\n","\n","df8.groupby('Gender').agg(np.sum)"]},{"cell_type":"markdown","metadata":{},"source":["Another way to see the size of each group is by applying the **size()** function as follows:-"]},{"cell_type":"code","execution_count":66,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["        User_ID  Product_ID     Age  Occupation  City_Category  \\\n","Gender                                                           \n","F        135809      135809  135809      135809         135809   \n","M        414259      414259  414259      414259         414259   \n","\n","        Stay_In_Current_City_Years  Marital_Status  Product_Category_1  \\\n","Gender                                                                   \n","F                           135809          135809              135809   \n","M                           414259          414259              414259   \n","\n","        Product_Category_2  Product_Category_3  Purchase  \n","Gender                                                    \n","F                 135809.0            135809.0    135809  \n","M                 414259.0            414259.0    414259  \n"]}],"source":["# attribute access in python pandas\n","\n","df8_grouped = df8.groupby('Gender')\n","\n","print(df8_grouped.agg(np.size))"]},{"cell_type":"markdown","metadata":{},"source":["### Applying multiple aggregation functions at once\n","\n","\n","With grouped Series, you can also pass a list or dict of functions to do aggregation with, and generate DataFrame as output as \n","follows:-"]},{"cell_type":"code","execution_count":67,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sum</th>\n","      <th>mean</th>\n","    </tr>\n","    <tr>\n","      <th>Gender</th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>F</th>\n","      <td>1186232642</td>\n","      <td>8734.565765</td>\n","    </tr>\n","    <tr>\n","      <th>M</th>\n","      <td>3909580100</td>\n","      <td>9437.526040</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["               sum         mean\n","Gender                         \n","F       1186232642  8734.565765\n","M       3909580100  9437.526040"]},"execution_count":67,"metadata":{},"output_type":"execute_result"}],"source":["df8.groupby('Gender')['Purchase'].agg([np.sum, np.mean])"]},{"cell_type":"markdown","metadata":{},"source":["### Transformations\n","\n","\n","Transformation on a group or a column returns an object that is indexed the same size of that is being grouped. \n","Thus, the transform should return a result that is the same size as that of a group chunk."]},{"cell_type":"code","execution_count":68,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["0    -0.764732\n","1    13.562236\n","2   -15.339224\n","3   -16.104867\n","4    -2.883881\n","Name: Purchase, dtype: float64\n"]}],"source":["df9=df.copy()\n","\n","\n","score = lambda x: (x - x.mean()) / x.std()*10\n","\n","\n","print(df9.groupby('Gender')['Purchase'].transform(score).head(5))"]},{"cell_type":"markdown","metadata":{},"source":["### Filtration\n","\n","\n","Filtration filters the data on a defined criteria and returns the subset of data. The **filter()** function is used to filter the data."]},{"cell_type":"code","execution_count":69,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>User_ID</th>\n","      <th>Product_ID</th>\n","      <th>Gender</th>\n","      <th>Age</th>\n","      <th>Occupation</th>\n","      <th>City_Category</th>\n","      <th>Stay_In_Current_City_Years</th>\n","      <th>Marital_Status</th>\n","      <th>Product_Category_1</th>\n","      <th>Product_Category_2</th>\n","      <th>Product_Category_3</th>\n","      <th>Purchase</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1000001</td>\n","      <td>P00069042</td>\n","      <td>F</td>\n","      <td>0-17</td>\n","      <td>10</td>\n","      <td>A</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>6.0</td>\n","      <td>14.0</td>\n","      <td>8370</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1000001</td>\n","      <td>P00248942</td>\n","      <td>F</td>\n","      <td>0-17</td>\n","      <td>10</td>\n","      <td>A</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>6.0</td>\n","      <td>14.0</td>\n","      <td>15200</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1000001</td>\n","      <td>P00087842</td>\n","      <td>F</td>\n","      <td>0-17</td>\n","      <td>10</td>\n","      <td>A</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>12</td>\n","      <td>6.0</td>\n","      <td>14.0</td>\n","      <td>1422</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1000001</td>\n","      <td>P00085442</td>\n","      <td>F</td>\n","      <td>0-17</td>\n","      <td>10</td>\n","      <td>A</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>12</td>\n","      <td>14.0</td>\n","      <td>14.0</td>\n","      <td>1057</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1000002</td>\n","      <td>P00285442</td>\n","      <td>M</td>\n","      <td>55+</td>\n","      <td>16</td>\n","      <td>C</td>\n","      <td>4+</td>\n","      <td>0</td>\n","      <td>8</td>\n","      <td>14.0</td>\n","      <td>14.0</td>\n","      <td>7969</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>550063</th>\n","      <td>1006033</td>\n","      <td>P00372445</td>\n","      <td>M</td>\n","      <td>51-55</td>\n","      <td>13</td>\n","      <td>B</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>20</td>\n","      <td>2.0</td>\n","      <td>11.0</td>\n","      <td>368</td>\n","    </tr>\n","    <tr>\n","      <th>550064</th>\n","      <td>1006035</td>\n","      <td>P00375436</td>\n","      <td>F</td>\n","      <td>26-35</td>\n","      <td>1</td>\n","      <td>C</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>20</td>\n","      <td>2.0</td>\n","      <td>11.0</td>\n","      <td>371</td>\n","    </tr>\n","    <tr>\n","      <th>550065</th>\n","      <td>1006036</td>\n","      <td>P00375436</td>\n","      <td>F</td>\n","      <td>26-35</td>\n","      <td>15</td>\n","      <td>B</td>\n","      <td>4+</td>\n","      <td>1</td>\n","      <td>20</td>\n","      <td>2.0</td>\n","      <td>11.0</td>\n","      <td>137</td>\n","    </tr>\n","    <tr>\n","      <th>550066</th>\n","      <td>1006038</td>\n","      <td>P00375436</td>\n","      <td>F</td>\n","      <td>55+</td>\n","      <td>1</td>\n","      <td>C</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>20</td>\n","      <td>2.0</td>\n","      <td>11.0</td>\n","      <td>365</td>\n","    </tr>\n","    <tr>\n","      <th>550067</th>\n","      <td>1006039</td>\n","      <td>P00371644</td>\n","      <td>F</td>\n","      <td>46-50</td>\n","      <td>0</td>\n","      <td>B</td>\n","      <td>4+</td>\n","      <td>1</td>\n","      <td>20</td>\n","      <td>2.0</td>\n","      <td>11.0</td>\n","      <td>490</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>550068 rows × 12 columns</p>\n","</div>"],"text/plain":["        User_ID Product_ID Gender    Age  Occupation City_Category  \\\n","0       1000001  P00069042      F   0-17          10             A   \n","1       1000001  P00248942      F   0-17          10             A   \n","2       1000001  P00087842      F   0-17          10             A   \n","3       1000001  P00085442      F   0-17          10             A   \n","4       1000002  P00285442      M    55+          16             C   \n","...         ...        ...    ...    ...         ...           ...   \n","550063  1006033  P00372445      M  51-55          13             B   \n","550064  1006035  P00375436      F  26-35           1             C   \n","550065  1006036  P00375436      F  26-35          15             B   \n","550066  1006038  P00375436      F    55+           1             C   \n","550067  1006039  P00371644      F  46-50           0             B   \n","\n","       Stay_In_Current_City_Years  Marital_Status  Product_Category_1  \\\n","0                               2               0                   3   \n","1                               2               0                   1   \n","2                               2               0                  12   \n","3                               2               0                  12   \n","4                              4+               0                   8   \n","...                           ...             ...                 ...   \n","550063                          1               1                  20   \n","550064                          3               0                  20   \n","550065                         4+               1                  20   \n","550066                          2               0                  20   \n","550067                         4+               1                  20   \n","\n","        Product_Category_2  Product_Category_3  Purchase  \n","0                      6.0                14.0      8370  \n","1                      6.0                14.0     15200  \n","2                      6.0                14.0      1422  \n","3                     14.0                14.0      1057  \n","4                     14.0                14.0      7969  \n","...                    ...                 ...       ...  \n","550063                 2.0                11.0       368  \n","550064                 2.0                11.0       371  \n","550065                 2.0                11.0       137  \n","550066                 2.0                11.0       365  \n","550067                 2.0                11.0       490  \n","\n","[550068 rows x 12 columns]"]},"execution_count":69,"metadata":{},"output_type":"execute_result"}],"source":["df10=df.copy()\n","\n","\n","df10.groupby('Gender').filter(lambda x: len(x) > 4)"]},{"cell_type":"markdown","metadata":{},"source":["# 25. Pandas merging and joining <a class=\"anchor\" id=\"25\"></a>\n","\n","\n","[Back to Table of Contents](#0.1)\n","\n","\n","Pandas has full-featured, high performance in-memory join operations that are very similar to relational databases like SQL. These methods perform significantly better than other open source implementations like base::merge.data.frame in R. The reason for this is careful algorithmic design and the internal layout of the data in DataFrame.\n","\n","\n","Pandas provides a single function, **merge**, as the entry point for all standard database join operations between DataFrame objects.\n","\n","\n","The syntax of the merge function is as follows:-\n","\n","\n","\n","`pd.merge(left, right, how='inner', on=None, left_on=None, right_on=None, left_index=False, right_index=False, sort=True)`\n","\n","\n","\n","The description of the parameters used is as follows−\n","\n","\n","- **left** − A DataFrame object.\n","\n","\n","- **right** − Another DataFrame object.\n","\n","\n","- **on** − Columns (names) to join on. Must be found in both the left and right DataFrame objects.\n","\n","\n","- **left_on** − Columns from the left DataFrame to use as keys. Can either be column names or arrays with length equal to the length of the DataFrame.\n","\n","\n","- **right_on** − Columns from the right DataFrame to use as keys. Can either be column names or arrays with length equal to the length of the DataFrame.\n","\n","\n","- **left_index** − If True, use the index (row labels) from the left DataFrame as its join key(s). In case of a DataFrame with a MultiIndex (hierarchical), the number of levels must match the number of join keys from the right DataFrame.\n","\n","\n","- **right_index** − Same usage as left_index for the right DataFrame.\n","\n","\n","- **how** − One of 'left', 'right', 'outer', 'inner'. Defaults to inner. \n","\n","\n","- **sort** − Sort the result DataFrame by the join keys in lexicographical order. Defaults to True, setting to False will improve the performance substantially in many cases.\n","\n","\n","Now, I will create two different DataFrames and perform the merging operations on them as follows:-"]},{"cell_type":"code","execution_count":70,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["   id    Name subject_id\n","0   1   Rohit       sub1\n","1   2  Dhawan       sub2\n","2   3   Virat       sub4\n","3   4   Dhoni       sub6\n","4   5   Kedar       sub5\n","   id     Name subject_id\n","0   1    Kumar       sub2\n","1   2   Bumrah       sub4\n","2   3    Shami       sub3\n","3   4  Kuldeep       sub6\n","4   5   Chahal       sub5\n"]}],"source":["# let's create two dataframes\n","\n","batsmen = pd.DataFrame({\n","   'id':[1,2,3,4,5],\n","   'Name': ['Rohit', 'Dhawan', 'Virat', 'Dhoni', 'Kedar'],\n","   'subject_id':['sub1','sub2','sub4','sub6','sub5']})\n","\n","bowler = pd.DataFrame(\n","   {'id':[1,2,3,4,5],\n","   'Name': ['Kumar', 'Bumrah', 'Shami', 'Kuldeep', 'Chahal'],\n","   'subject_id':['sub2','sub4','sub3','sub6','sub5']})\n","\n","\n","print(batsmen)\n","\n","\n","print(bowler)"]},{"cell_type":"code","execution_count":71,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>Name_x</th>\n","      <th>subject_id_x</th>\n","      <th>Name_y</th>\n","      <th>subject_id_y</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>Rohit</td>\n","      <td>sub1</td>\n","      <td>Kumar</td>\n","      <td>sub2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>Dhawan</td>\n","      <td>sub2</td>\n","      <td>Bumrah</td>\n","      <td>sub4</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>Virat</td>\n","      <td>sub4</td>\n","      <td>Shami</td>\n","      <td>sub3</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>Dhoni</td>\n","      <td>sub6</td>\n","      <td>Kuldeep</td>\n","      <td>sub6</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>Kedar</td>\n","      <td>sub5</td>\n","      <td>Chahal</td>\n","      <td>sub5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   id  Name_x subject_id_x   Name_y subject_id_y\n","0   1   Rohit         sub1    Kumar         sub2\n","1   2  Dhawan         sub2   Bumrah         sub4\n","2   3   Virat         sub4    Shami         sub3\n","3   4   Dhoni         sub6  Kuldeep         sub6\n","4   5   Kedar         sub5   Chahal         sub5"]},"execution_count":71,"metadata":{},"output_type":"execute_result"}],"source":["# merge two dataframes on a key\n","\n","pd.merge(batsmen, bowler, on='id')"]},{"cell_type":"code","execution_count":72,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>Name_x</th>\n","      <th>subject_id</th>\n","      <th>Name_y</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>4</td>\n","      <td>Dhoni</td>\n","      <td>sub6</td>\n","      <td>Kuldeep</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>5</td>\n","      <td>Kedar</td>\n","      <td>sub5</td>\n","      <td>Chahal</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   id Name_x subject_id   Name_y\n","0   4  Dhoni       sub6  Kuldeep\n","1   5  Kedar       sub5   Chahal"]},"execution_count":72,"metadata":{},"output_type":"execute_result"}],"source":["# merge two dataframes on multiple keys\n","\n","pd.merge(batsmen, bowler, on=['id', 'subject_id'])"]},{"cell_type":"markdown","metadata":{},"source":["### Merge using 'how' argument\n","\n","\n","\n","The **how** argument to merge specifies how to determine which keys are to be included in the resulting table. If a key combination does not appear in either the left or the right tables, the values in the joined table will be **NA**.\n","\n","\n","Here is a summary of the how options and their SQL equivalent names −\n","\n","\n","\n","- **Merge Method** -\t**SQL Equivalent**\t-  **Description**\n","\n","\n","-  left            -     LEFT OUTER JOIN\t-   Use keys from left object\n","\n","\n","- right\t           -     RIGHT OUTER JOIN\t-   Use keys from right object\n","\n","\n","- outer\t           -     FULL OUTER JOIN\t-   Use union of keys\n","\n","\n","- inner\t           -     INNER JOIN\t        -   Use intersection of keys"]},{"cell_type":"code","execution_count":73,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id_x</th>\n","      <th>Name_x</th>\n","      <th>subject_id</th>\n","      <th>id_y</th>\n","      <th>Name_y</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>Rohit</td>\n","      <td>sub1</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>Dhawan</td>\n","      <td>sub2</td>\n","      <td>1.0</td>\n","      <td>Kumar</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>Virat</td>\n","      <td>sub4</td>\n","      <td>2.0</td>\n","      <td>Bumrah</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>Dhoni</td>\n","      <td>sub6</td>\n","      <td>4.0</td>\n","      <td>Kuldeep</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>Kedar</td>\n","      <td>sub5</td>\n","      <td>5.0</td>\n","      <td>Chahal</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   id_x  Name_x subject_id  id_y   Name_y\n","0     1   Rohit       sub1   NaN      NaN\n","1     2  Dhawan       sub2   1.0    Kumar\n","2     3   Virat       sub4   2.0   Bumrah\n","3     4   Dhoni       sub6   4.0  Kuldeep\n","4     5   Kedar       sub5   5.0   Chahal"]},"execution_count":73,"metadata":{},"output_type":"execute_result"}],"source":["# left join\n","\n","pd.merge(batsmen, bowler, on='subject_id', how='left')"]},{"cell_type":"code","execution_count":74,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id_x</th>\n","      <th>Name_x</th>\n","      <th>subject_id</th>\n","      <th>id_y</th>\n","      <th>Name_y</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2.0</td>\n","      <td>Dhawan</td>\n","      <td>sub2</td>\n","      <td>1</td>\n","      <td>Kumar</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>3.0</td>\n","      <td>Virat</td>\n","      <td>sub4</td>\n","      <td>2</td>\n","      <td>Bumrah</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>4.0</td>\n","      <td>Dhoni</td>\n","      <td>sub6</td>\n","      <td>4</td>\n","      <td>Kuldeep</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>5.0</td>\n","      <td>Kedar</td>\n","      <td>sub5</td>\n","      <td>5</td>\n","      <td>Chahal</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>sub3</td>\n","      <td>3</td>\n","      <td>Shami</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   id_x  Name_x subject_id  id_y   Name_y\n","0   2.0  Dhawan       sub2     1    Kumar\n","1   3.0   Virat       sub4     2   Bumrah\n","2   4.0   Dhoni       sub6     4  Kuldeep\n","3   5.0   Kedar       sub5     5   Chahal\n","4   NaN     NaN       sub3     3    Shami"]},"execution_count":74,"metadata":{},"output_type":"execute_result"}],"source":["# right join\n","\n","pd.merge(batsmen, bowler, on='subject_id', how='right')"]},{"cell_type":"code","execution_count":75,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id_x</th>\n","      <th>Name_x</th>\n","      <th>subject_id</th>\n","      <th>id_y</th>\n","      <th>Name_y</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1.0</td>\n","      <td>Rohit</td>\n","      <td>sub1</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2.0</td>\n","      <td>Dhawan</td>\n","      <td>sub2</td>\n","      <td>1.0</td>\n","      <td>Kumar</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3.0</td>\n","      <td>Virat</td>\n","      <td>sub4</td>\n","      <td>2.0</td>\n","      <td>Bumrah</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4.0</td>\n","      <td>Dhoni</td>\n","      <td>sub6</td>\n","      <td>4.0</td>\n","      <td>Kuldeep</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5.0</td>\n","      <td>Kedar</td>\n","      <td>sub5</td>\n","      <td>5.0</td>\n","      <td>Chahal</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>sub3</td>\n","      <td>3.0</td>\n","      <td>Shami</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   id_x  Name_x subject_id  id_y   Name_y\n","0   1.0   Rohit       sub1   NaN      NaN\n","1   2.0  Dhawan       sub2   1.0    Kumar\n","2   3.0   Virat       sub4   2.0   Bumrah\n","3   4.0   Dhoni       sub6   4.0  Kuldeep\n","4   5.0   Kedar       sub5   5.0   Chahal\n","5   NaN     NaN       sub3   3.0    Shami"]},"execution_count":75,"metadata":{},"output_type":"execute_result"}],"source":["# outer join\n","\n","pd.merge(batsmen, bowler, on='subject_id', how='outer')"]},{"cell_type":"code","execution_count":76,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id_x</th>\n","      <th>Name_x</th>\n","      <th>subject_id</th>\n","      <th>id_y</th>\n","      <th>Name_y</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2</td>\n","      <td>Dhawan</td>\n","      <td>sub2</td>\n","      <td>1</td>\n","      <td>Kumar</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>3</td>\n","      <td>Virat</td>\n","      <td>sub4</td>\n","      <td>2</td>\n","      <td>Bumrah</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>4</td>\n","      <td>Dhoni</td>\n","      <td>sub6</td>\n","      <td>4</td>\n","      <td>Kuldeep</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>5</td>\n","      <td>Kedar</td>\n","      <td>sub5</td>\n","      <td>5</td>\n","      <td>Chahal</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   id_x  Name_x subject_id  id_y   Name_y\n","0     2  Dhawan       sub2     1    Kumar\n","1     3   Virat       sub4     2   Bumrah\n","2     4   Dhoni       sub6     4  Kuldeep\n","3     5   Kedar       sub5     5   Chahal"]},"execution_count":76,"metadata":{},"output_type":"execute_result"}],"source":["# inner join\n","\n","pd.merge(batsmen, bowler, on='subject_id', how='inner')"]},{"cell_type":"markdown","metadata":{},"source":["# 26. Pandas concatenation operation <a class=\"anchor\" id=\"26\"></a>\n","\n","\n","[Back to Table of Contents](#0.1)\n","\n","\n","\n","Pandas provides various facilities for easily combining together Series, DataFrame, and Panel objects.\n","\n","\n","The **concat()** function does all of the heavy lifting of performing concatenation operations along an axis while performing optional set logic (union or intersection) of the indexes (if any) on the other axes.\n","\n","\n","The syntax of the **concat()** function is as follows:-\n","\n","\n","\n","`pd.concat(objs, axis=0, join='outer', join_axes=None, ignore_index=False, keys=None, levels=None, names=None, verify_integrity=False, copy=True)`\n","\n","\n","\n","The description of the arguments is as follows:-\n","\n","\n","\n","- **objs** − This is a sequence or mapping of Series, DataFrame, or Panel objects.\n","\n","\n","- **axis** − {0, 1, ...}, default 0. This is the axis to concatenate along.\n","\n","\n","- **join** − {'inner', 'outer'}, default 'outer'. How to handle indexes on other axis(es). Outer for union and inner for intersection.\n","\n","\n","- **ignore_index** − boolean, default False. If True, do not use the index values on the concatenation axis. The resulting axis will be labeled 0, ..., n - 1.\n","\n","\n","- **join_axes** − This is the list of index objects. Specific indexes to use for the other (n-1) axes instead of performing inner/outer set logic.\n","\n","\n","- **keys** : sequence, default None. Construct hierarchical index using the passed keys as the outermost level. If multiple levels passed, should contain tuples.\n","\n","\n","- **levels** : list of sequences, default None. Specific levels (unique values) to use for constructing a MultiIndex. Otherwise they will be inferred from the keys.\n","\n","\n","- **names** : list, default None. Names for the levels in the resulting hierarchical index.\n","\n","\n","- **verify_integrity** : boolean, default False. Check whether the new concatenated axis contains duplicates. This can be very expensive relative to the actual data concatenation.\n","\n","\n","- **copy** : boolean, default True. If False, do not copy data unnecessarily.\n","\n","\n","Now, I will create two dataframes and do concatenation:-"]},{"cell_type":"code","execution_count":77,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["   id    Name subject_id\n","0   1   Rohit       sub1\n","1   2  Dhawan       sub2\n","2   3   Virat       sub4\n","3   4   Dhoni       sub6\n","4   5   Kedar       sub5\n","   id     Name subject_id\n","0   1    Kumar       sub2\n","1   2   Bumrah       sub4\n","2   3    Shami       sub3\n","3   4  Kuldeep       sub6\n","4   5   Chahal       sub5\n"]}],"source":["# let's create two dataframes\n","\n","batsmen = pd.DataFrame({\n","   'id':[1,2,3,4,5],\n","   'Name': ['Rohit', 'Dhawan', 'Virat', 'Dhoni', 'Kedar'],\n","   'subject_id':['sub1','sub2','sub4','sub6','sub5']})\n","\n","bowler = pd.DataFrame(\n","   {'id':[1,2,3,4,5],\n","   'Name': ['Kumar', 'Bumrah', 'Shami', 'Kuldeep', 'Chahal'],\n","   'subject_id':['sub2','sub4','sub3','sub6','sub5']})\n","\n","\n","print(batsmen)\n","\n","\n","print(bowler)"]},{"cell_type":"code","execution_count":78,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>Name</th>\n","      <th>subject_id</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>Rohit</td>\n","      <td>sub1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>Dhawan</td>\n","      <td>sub2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>Virat</td>\n","      <td>sub4</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>Dhoni</td>\n","      <td>sub6</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>Kedar</td>\n","      <td>sub5</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>Kumar</td>\n","      <td>sub2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>Bumrah</td>\n","      <td>sub4</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>Shami</td>\n","      <td>sub3</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>Kuldeep</td>\n","      <td>sub6</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>Chahal</td>\n","      <td>sub5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   id     Name subject_id\n","0   1    Rohit       sub1\n","1   2   Dhawan       sub2\n","2   3    Virat       sub4\n","3   4    Dhoni       sub6\n","4   5    Kedar       sub5\n","0   1    Kumar       sub2\n","1   2   Bumrah       sub4\n","2   3    Shami       sub3\n","3   4  Kuldeep       sub6\n","4   5   Chahal       sub5"]},"execution_count":78,"metadata":{},"output_type":"execute_result"}],"source":["# concatenate the dataframes\n","\n","\n","team=[batsmen, bowler]\n","\n","pd.concat(team)"]},{"cell_type":"code","execution_count":79,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th></th>\n","      <th>id</th>\n","      <th>Name</th>\n","      <th>subject_id</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th rowspan=\"5\" valign=\"top\">x</th>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>Rohit</td>\n","      <td>sub1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>Dhawan</td>\n","      <td>sub2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>Virat</td>\n","      <td>sub4</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>Dhoni</td>\n","      <td>sub6</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>Kedar</td>\n","      <td>sub5</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"5\" valign=\"top\">y</th>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>Kumar</td>\n","      <td>sub2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>Bumrah</td>\n","      <td>sub4</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>Shami</td>\n","      <td>sub3</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>Kuldeep</td>\n","      <td>sub6</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>Chahal</td>\n","      <td>sub5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     id     Name subject_id\n","x 0   1    Rohit       sub1\n","  1   2   Dhawan       sub2\n","  2   3    Virat       sub4\n","  3   4    Dhoni       sub6\n","  4   5    Kedar       sub5\n","y 0   1    Kumar       sub2\n","  1   2   Bumrah       sub4\n","  2   3    Shami       sub3\n","  3   4  Kuldeep       sub6\n","  4   5   Chahal       sub5"]},"execution_count":79,"metadata":{},"output_type":"execute_result"}],"source":["# associate keys with the dataframes\n","\n","pd.concat(team, keys=['x', 'y'])"]},{"cell_type":"markdown","metadata":{},"source":["We can see the index of the resultant dataframe is duplicated. So each index is repeated.\n","\n","If the resultant object has to follow its own indexing, we can set **ignore_index** option to True as follows:-"]},{"cell_type":"code","execution_count":80,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>Name</th>\n","      <th>subject_id</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>Rohit</td>\n","      <td>sub1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>Dhawan</td>\n","      <td>sub2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>Virat</td>\n","      <td>sub4</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>Dhoni</td>\n","      <td>sub6</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>Kedar</td>\n","      <td>sub5</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>1</td>\n","      <td>Kumar</td>\n","      <td>sub2</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>2</td>\n","      <td>Bumrah</td>\n","      <td>sub4</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>3</td>\n","      <td>Shami</td>\n","      <td>sub3</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>4</td>\n","      <td>Kuldeep</td>\n","      <td>sub6</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>5</td>\n","      <td>Chahal</td>\n","      <td>sub5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   id     Name subject_id\n","0   1    Rohit       sub1\n","1   2   Dhawan       sub2\n","2   3    Virat       sub4\n","3   4    Dhoni       sub6\n","4   5    Kedar       sub5\n","5   1    Kumar       sub2\n","6   2   Bumrah       sub4\n","7   3    Shami       sub3\n","8   4  Kuldeep       sub6\n","9   5   Chahal       sub5"]},"execution_count":80,"metadata":{},"output_type":"execute_result"}],"source":["pd.concat(team, keys=['x', 'y'], ignore_index=True)"]},{"cell_type":"markdown","metadata":{},"source":["We can see that the index changes completely and the Keys are also overridden."]},{"cell_type":"markdown","metadata":{},"source":["If two objects need to be added along axis=1, then the new columns will be appended as follows:-"]},{"cell_type":"code","execution_count":81,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>Name</th>\n","      <th>subject_id</th>\n","      <th>id</th>\n","      <th>Name</th>\n","      <th>subject_id</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>Rohit</td>\n","      <td>sub1</td>\n","      <td>1</td>\n","      <td>Kumar</td>\n","      <td>sub2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>Dhawan</td>\n","      <td>sub2</td>\n","      <td>2</td>\n","      <td>Bumrah</td>\n","      <td>sub4</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>Virat</td>\n","      <td>sub4</td>\n","      <td>3</td>\n","      <td>Shami</td>\n","      <td>sub3</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>Dhoni</td>\n","      <td>sub6</td>\n","      <td>4</td>\n","      <td>Kuldeep</td>\n","      <td>sub6</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>Kedar</td>\n","      <td>sub5</td>\n","      <td>5</td>\n","      <td>Chahal</td>\n","      <td>sub5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   id    Name subject_id  id     Name subject_id\n","0   1   Rohit       sub1   1    Kumar       sub2\n","1   2  Dhawan       sub2   2   Bumrah       sub4\n","2   3   Virat       sub4   3    Shami       sub3\n","3   4   Dhoni       sub6   4  Kuldeep       sub6\n","4   5   Kedar       sub5   5   Chahal       sub5"]},"execution_count":81,"metadata":{},"output_type":"execute_result"}],"source":["pd.concat(team, axis=1)"]},{"cell_type":"markdown","metadata":{},"source":["### Concatenating using append\n","\n","\n","A useful shortcut to concat are the append instance methods on Series and DataFrame. These methods actually predated concat. They concatenate along axis=0, namely the index as follows:−"]},{"cell_type":"code","execution_count":82,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>Name</th>\n","      <th>subject_id</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>Rohit</td>\n","      <td>sub1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>Dhawan</td>\n","      <td>sub2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>Virat</td>\n","      <td>sub4</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>Dhoni</td>\n","      <td>sub6</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>Kedar</td>\n","      <td>sub5</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>Kumar</td>\n","      <td>sub2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>Bumrah</td>\n","      <td>sub4</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>Shami</td>\n","      <td>sub3</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>Kuldeep</td>\n","      <td>sub6</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>Chahal</td>\n","      <td>sub5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   id     Name subject_id\n","0   1    Rohit       sub1\n","1   2   Dhawan       sub2\n","2   3    Virat       sub4\n","3   4    Dhoni       sub6\n","4   5    Kedar       sub5\n","0   1    Kumar       sub2\n","1   2   Bumrah       sub4\n","2   3    Shami       sub3\n","3   4  Kuldeep       sub6\n","4   5   Chahal       sub5"]},"execution_count":82,"metadata":{},"output_type":"execute_result"}],"source":["batsmen.append(bowler)"]},{"cell_type":"markdown","metadata":{},"source":["# 27. Reshaping by melt and pivot <a class=\"anchor\" id=\"27\"></a>\n","\n","\n","[Back to Table of Contents](#0.1)\n","\n","\n","\n","### Melt creates wide-to-long format dataframe\n","\n","\n","\n","When we take a closer look at our original dataframe, we can see that our dataset is not in the tidy data format.\n","\n","The columns `Product_Category_1`, `Product_Category_2` and `Product_Category_3` contain values of product_category rather than variables. We should reorganize our dataframe into tidy data format.\n","\n","The **melt()** function is useful to convert a DataFrame from **wide-to-long** format where one or more columns are identifier variables, while all other columns are considered measured variables. The measured variables are then \"unpivoted\" to the row axis, leaving non-identifier columns, \"variable\" and \"value\". The names of those columns can be customized by supplying the var_name and value_name parameters.\n","\n","We can convert our dataset into long data format using the **melt()** function as follows:-"]},{"cell_type":"code","execution_count":83,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["Index(['User_ID', 'Product_ID', 'Gender', 'Age', 'Occupation', 'City_Category',\n","       'Stay_In_Current_City_Years', 'Marital_Status', 'Product_Category_1',\n","       'Product_Category_2', 'Product_Category_3', 'Purchase'],\n","      dtype='object')"]},"execution_count":83,"metadata":{},"output_type":"execute_result"}],"source":["df11=df.copy()\n","\n","df11.columns"]},{"cell_type":"code","execution_count":84,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>User_ID</th>\n","      <th>Product_ID</th>\n","      <th>Gender</th>\n","      <th>Age</th>\n","      <th>Occupation</th>\n","      <th>City_Category</th>\n","      <th>Marital_Status</th>\n","      <th>Purchase</th>\n","      <th>Product_Category</th>\n","      <th>Amount</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1000001</td>\n","      <td>P00069042</td>\n","      <td>F</td>\n","      <td>0-17</td>\n","      <td>10</td>\n","      <td>A</td>\n","      <td>0</td>\n","      <td>8370</td>\n","      <td>Product_Category_1</td>\n","      <td>3.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1000001</td>\n","      <td>P00248942</td>\n","      <td>F</td>\n","      <td>0-17</td>\n","      <td>10</td>\n","      <td>A</td>\n","      <td>0</td>\n","      <td>15200</td>\n","      <td>Product_Category_1</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1000001</td>\n","      <td>P00087842</td>\n","      <td>F</td>\n","      <td>0-17</td>\n","      <td>10</td>\n","      <td>A</td>\n","      <td>0</td>\n","      <td>1422</td>\n","      <td>Product_Category_1</td>\n","      <td>12.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1000001</td>\n","      <td>P00085442</td>\n","      <td>F</td>\n","      <td>0-17</td>\n","      <td>10</td>\n","      <td>A</td>\n","      <td>0</td>\n","      <td>1057</td>\n","      <td>Product_Category_1</td>\n","      <td>12.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1000002</td>\n","      <td>P00285442</td>\n","      <td>M</td>\n","      <td>55+</td>\n","      <td>16</td>\n","      <td>C</td>\n","      <td>0</td>\n","      <td>7969</td>\n","      <td>Product_Category_1</td>\n","      <td>8.0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>1000003</td>\n","      <td>P00193542</td>\n","      <td>M</td>\n","      <td>26-35</td>\n","      <td>15</td>\n","      <td>A</td>\n","      <td>0</td>\n","      <td>15227</td>\n","      <td>Product_Category_1</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>1000004</td>\n","      <td>P00184942</td>\n","      <td>M</td>\n","      <td>46-50</td>\n","      <td>7</td>\n","      <td>B</td>\n","      <td>1</td>\n","      <td>19215</td>\n","      <td>Product_Category_1</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>1000004</td>\n","      <td>P00346142</td>\n","      <td>M</td>\n","      <td>46-50</td>\n","      <td>7</td>\n","      <td>B</td>\n","      <td>1</td>\n","      <td>15854</td>\n","      <td>Product_Category_1</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>1000004</td>\n","      <td>P0097242</td>\n","      <td>M</td>\n","      <td>46-50</td>\n","      <td>7</td>\n","      <td>B</td>\n","      <td>1</td>\n","      <td>15686</td>\n","      <td>Product_Category_1</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>1000005</td>\n","      <td>P00274942</td>\n","      <td>M</td>\n","      <td>26-35</td>\n","      <td>20</td>\n","      <td>A</td>\n","      <td>1</td>\n","      <td>7871</td>\n","      <td>Product_Category_1</td>\n","      <td>8.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   User_ID Product_ID Gender    Age  Occupation City_Category  Marital_Status  \\\n","0  1000001  P00069042      F   0-17          10             A               0   \n","1  1000001  P00248942      F   0-17          10             A               0   \n","2  1000001  P00087842      F   0-17          10             A               0   \n","3  1000001  P00085442      F   0-17          10             A               0   \n","4  1000002  P00285442      M    55+          16             C               0   \n","5  1000003  P00193542      M  26-35          15             A               0   \n","6  1000004  P00184942      M  46-50           7             B               1   \n","7  1000004  P00346142      M  46-50           7             B               1   \n","8  1000004   P0097242      M  46-50           7             B               1   \n","9  1000005  P00274942      M  26-35          20             A               1   \n","\n","   Purchase    Product_Category  Amount  \n","0      8370  Product_Category_1     3.0  \n","1     15200  Product_Category_1     1.0  \n","2      1422  Product_Category_1    12.0  \n","3      1057  Product_Category_1    12.0  \n","4      7969  Product_Category_1     8.0  \n","5     15227  Product_Category_1     1.0  \n","6     19215  Product_Category_1     1.0  \n","7     15854  Product_Category_1     1.0  \n","8     15686  Product_Category_1     1.0  \n","9      7871  Product_Category_1     8.0  "]},"execution_count":84,"metadata":{},"output_type":"execute_result"}],"source":["df12=(pd.melt(frame=df11, id_vars=['User_ID','Product_ID', 'Gender','Age','Occupation','City_Category',\n","                             'Marital_Status','Purchase'],                          \n","                    value_vars=['Product_Category_1','Product_Category_2','Product_Category_3'], \n","                    var_name='Product_Category', value_name='Amount'))\n","\n","df12.head(10)"]},{"cell_type":"markdown","metadata":{},"source":["### Pivot creates long-to-wide format dataframe\n","\n","\n","I have melt three columns `Product_Category_1`, `Product_Category_2` and `Product_Category_3` into a single column named\n","`Product_Category` with **melt()** function. So, I have converted the above dataframe from wide to long format.\n","\n","\n","Now, I will convert the above column `Product_Category` from long to wide format with **pivot()** function. \n","**pivot()** function takes 3 arguments with the following names - index, columns, and values. As a value for each of these parameters we need to specify a column name in the original table. Then the **pivot()** function will create a new table, \n","whose row and column indices are the unique values of the respective parameters. The cell values of the new table are taken \n","from column given as the values parameter.\n","\n","\n","This is illustrated below:-"]},{"cell_type":"code","execution_count":85,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th>Product_Category</th>\n","      <th>Product_Category_1</th>\n","      <th>Product_Category_2</th>\n","      <th>Product_Category_3</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>3.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>12.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>12.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>8.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>1.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>1.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>1.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>1.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>8.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>5.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>8.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>8.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>1.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>5.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>4.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>2.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>5.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>1.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>1.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>5.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>8.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>8.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>8.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>1.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["Product_Category  Product_Category_1  Product_Category_2  Product_Category_3\n","0                                3.0                 NaN                 NaN\n","1                                1.0                 NaN                 NaN\n","2                               12.0                 NaN                 NaN\n","3                               12.0                 NaN                 NaN\n","4                                8.0                 NaN                 NaN\n","5                                1.0                 NaN                 NaN\n","6                                1.0                 NaN                 NaN\n","7                                1.0                 NaN                 NaN\n","8                                1.0                 NaN                 NaN\n","9                                8.0                 NaN                 NaN\n","10                               5.0                 NaN                 NaN\n","11                               8.0                 NaN                 NaN\n","12                               8.0                 NaN                 NaN\n","13                               1.0                 NaN                 NaN\n","14                               5.0                 NaN                 NaN\n","15                               4.0                 NaN                 NaN\n","16                               2.0                 NaN                 NaN\n","17                               5.0                 NaN                 NaN\n","18                               1.0                 NaN                 NaN\n","19                               1.0                 NaN                 NaN\n","20                               5.0                 NaN                 NaN\n","21                               8.0                 NaN                 NaN\n","22                               8.0                 NaN                 NaN\n","23                               8.0                 NaN                 NaN\n","24                               1.0                 NaN                 NaN"]},"execution_count":85,"metadata":{},"output_type":"execute_result"}],"source":["df13=df12[['Product_Category', 'Amount']]\n","\n","df14=df13.pivot(index=None, columns='Product_Category', values='Amount')\n","\n","df14.head(25)"]},{"cell_type":"markdown","metadata":{},"source":["### Reshaping with pivot_table function\n","\n","\n","Before calling the pivot() function, we need to ensure that our dataset does not have rows with duplicate values for the specified columns. If there are duplicate entries for rows in the dataset, the pivot() function, will throw a value error.\n","\n","In this case, the **pivot_table()** method comes to rescue. It works like pivot, but it aggregates the values from rows with duplicate entries for the specified columns. The syntax of the pivot_table() function is given below:-\n","\n","\n","`df.pivot_table(values=None, index=None, columns=None, aggfunc='mean', fill_value=None, \n","margins=False, dropna=True, margins_name='All')`"]},{"cell_type":"markdown","metadata":{},"source":["# 28. Reshaping by stacking and unstacking <a class=\"anchor\" id=\"28\"></a>\n","\n","\n","[Back to Table of Contents](#0.1)\n","\n","\n","There are two other methods called **stack()** and **unstack()** which closely resemble the **pivot()** method. These methods are designed to work together with multiindex objects. The functionality of these methods is described below:-\n","\n","\n","\n","### Stacking\n","\n","\n","Stacking means \"pivot\" a level of the (possibly hierarchical) column labels, returning a DataFrame with an index with a new inner-most level of row labels. So. stacking a dataframe means moving or pivoting the innermost column index to become the innermost row index. \n","\n","\n","It return a reshaped dataframe or series having a multi-level index with one or more new inner-most levels compared to the current dataframe. The new inner-most levels are created by pivoting the columns of the current dataframe.\n","\n","\n","\n","- if the columns have a single level, the output is a Series.\n","\n","\n","- if the columns have multiple levels, the new index level(s) is (are) taken from the prescribed level(s) and the output is a DataFrame.\n","\n","\n","In this case, we look at a dataframe with single level hierarchical indices on both axes. Stacking takes the most-inner column index (height, weight), makes it the most inner row index and reshuffles the cell values accordingly. "]},{"cell_type":"code","execution_count":86,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead tr th {\n","        text-align: left;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr>\n","      <th></th>\n","      <th colspan=\"2\" halign=\"left\">weight</th>\n","    </tr>\n","    <tr>\n","      <th></th>\n","      <th>kg</th>\n","      <th>pounds</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>husband</th>\n","      <td>75</td>\n","      <td>165</td>\n","    </tr>\n","    <tr>\n","      <th>wife</th>\n","      <td>60</td>\n","      <td>132</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        weight       \n","            kg pounds\n","husband     75    165\n","wife        60    132"]},"execution_count":86,"metadata":{},"output_type":"execute_result"}],"source":["cols=pd.MultiIndex.from_tuples([('weight', 'kg'), ('weight', 'pounds')])\n","\n","df15=pd.DataFrame([[75,165], [60, 132]],\n","                 index=['husband', 'wife'],\n","                 columns=cols)\n","\n","df15"]},{"cell_type":"code","execution_count":87,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th></th>\n","      <th>weight</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th rowspan=\"2\" valign=\"top\">husband</th>\n","      <th>kg</th>\n","      <td>75</td>\n","    </tr>\n","    <tr>\n","      <th>pounds</th>\n","      <td>165</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"2\" valign=\"top\">wife</th>\n","      <th>kg</th>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>pounds</th>\n","      <td>132</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                weight\n","husband kg          75\n","        pounds     165\n","wife    kg          60\n","        pounds     132"]},"execution_count":87,"metadata":{},"output_type":"execute_result"}],"source":["df16=df15.stack()\n","\n","df16"]},{"cell_type":"markdown","metadata":{},"source":["### Unstacking\n","\n","\n","It is the inverse operation of stacking. It means \"pivot\" a level of the (possibly hierarchical) row index to the column axis, producing a reshaped dataframe with a new inner-most level of column labels.\n","\n","\n","I will convert the stacked dataframe df16 back to original form as follows:-"]},{"cell_type":"code","execution_count":88,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead tr th {\n","        text-align: left;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr>\n","      <th></th>\n","      <th colspan=\"2\" halign=\"left\">weight</th>\n","    </tr>\n","    <tr>\n","      <th></th>\n","      <th>kg</th>\n","      <th>pounds</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>husband</th>\n","      <td>75</td>\n","      <td>165</td>\n","    </tr>\n","    <tr>\n","      <th>wife</th>\n","      <td>60</td>\n","      <td>132</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        weight       \n","            kg pounds\n","husband     75    165\n","wife        60    132"]},"execution_count":88,"metadata":{},"output_type":"execute_result"}],"source":["df16.unstack()"]},{"cell_type":"markdown","metadata":{},"source":["# 29. Options and customization with pandas <a class=\"anchor\" id=\"29\"></a>\n","\n","\n","[Back to Table of Contents](#0.1)\n","\n","\n","\n","Pandas provide API to customize some aspects of its behavior. In most cases, we would like to adjust the display related options.\n","\n","\n","The API is composed of five relevant functions. They are as follows :−\n","\n","\n","- 1. **get_option()**\n","\n","\n","- 2. **set_option()**\n","\n","\n","- 3. **reset_option()**\n","\n","\n","- 4. **describe_option()**\n","\n","\n","- 5. **option_context()**\n","\n","\n","Let us now understand how the functions operate."]},{"cell_type":"markdown","metadata":{},"source":["### 1. get_option(param)\n","\n","\n","\n","**get_option()** takes a single parameter and returns the value as given in the output below −"]},{"cell_type":"code","execution_count":89,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["60"]},"execution_count":89,"metadata":{},"output_type":"execute_result"}],"source":["# display maximum rows\n","\n","pd.get_option(\"display.max_rows\")"]},{"cell_type":"code","execution_count":90,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["20"]},"execution_count":90,"metadata":{},"output_type":"execute_result"}],"source":["# display maximum columns\n","\n","pd.get_option(\"display.max_columns\")"]},{"cell_type":"markdown","metadata":{},"source":["### 2. set_option(param,value)\n","\n","\n","**set_option()** takes two arguments and sets the value to the parameter as shown below −"]},{"cell_type":"code","execution_count":91,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["80"]},"execution_count":91,"metadata":{},"output_type":"execute_result"}],"source":["# set maximum rows\n","\n","pd.set_option(\"display.max_rows\", 80)\n","\n","pd.get_option(\"display.max_rows\")"]},{"cell_type":"code","execution_count":92,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["30"]},"execution_count":92,"metadata":{},"output_type":"execute_result"}],"source":["# set maximum columns\n","\n","pd.set_option(\"display.max_columns\", 30)\n","\n","pd.get_option(\"display.max_columns\")"]},{"cell_type":"markdown","metadata":{},"source":["### 3. reset_option(param)\n","\n","\n","**reset_option()** takes an argument and sets the value back to the default value."]},{"cell_type":"code","execution_count":93,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["60"]},"execution_count":93,"metadata":{},"output_type":"execute_result"}],"source":["# display maximum rows\n","\n","pd.reset_option(\"display.max_rows\")\n","\n","pd.get_option(\"display.max_rows\")"]},{"cell_type":"code","execution_count":94,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["20"]},"execution_count":94,"metadata":{},"output_type":"execute_result"}],"source":["# display maximum columns\n","\n","pd.reset_option(\"display.max_columns\")\n","\n","pd.get_option(\"display.max_columns\")"]},{"cell_type":"markdown","metadata":{},"source":["### 4. describe_option(param)\n","\n","\n","**describe_option()** prints the description of the argument."]},{"cell_type":"code","execution_count":95,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["display.max_rows : int\n","    If max_rows is exceeded, switch to truncate view. Depending on\n","    `large_repr`, objects are either centrally truncated or printed as\n","    a summary view. 'None' value means unlimited.\n","\n","    In case python/IPython is running in a terminal and `large_repr`\n","    equals 'truncate' this can be set to 0 and pandas will auto-detect\n","    the height of the terminal and print a truncated object which fits\n","    the screen height. The IPython notebook, IPython qtconsole, or\n","    IDLE do not run in a terminal and hence it is not possible to do\n","    correct auto-detection.\n","    [default: 60] [currently: 60]\n"]}],"source":["# description of the display maximum rows parameter\n","\n","pd.describe_option(\"display.max_rows\")"]},{"cell_type":"markdown","metadata":{},"source":["### 5. option_context()\n","\n","\n","**option_context()** context manager is used to set the option in with statement temporarily. Option values are restored automatically when you exit with block."]},{"cell_type":"code","execution_count":96,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["10\n","10\n"]}],"source":["# set the parameter value with option_context\n","\n","with pd.option_context(\"display.max_rows\",10):\n","   print(pd.get_option(\"display.max_rows\"))\n","   print(pd.get_option(\"display.max_rows\"))"]},{"cell_type":"markdown","metadata":{},"source":["There is a difference between the first and the second print statements. The first statement prints the value set by **option_context()** which is temporary within the with context itself. After the with context, the second print statement prints the configured value."]},{"cell_type":"markdown","metadata":{},"source":["# 30. Summary and conclusion <a class=\"anchor\" id=\"30\"></a>\n","\n","\n","[Back to Table of Contents](#0.1)\n","\n","\n","- In this kernel, I have explored pandas and important data analysis tools of pandas. \n","\n","- I have used the Black Friday dataset and explore various functionalities offered by pandas.\n","\n","- I have shed light on important functionalities of pandas like **aggregations in pandas**, **iteration in pandas**, **Pandas GroupBy operations**, **Pandas merging and joining**.\n","\n","- I have also discussed **Pandas concatenation operation**, **Reshaping by melt and pivot** and **Reshaping by stacking and unstacking**.\n","\n","- I have also discussed **basic functionality in Pandas**, **descriptive statistics in Pandas** and **statistical functions in Pandas**.\n","\n","- Lastly, I have discussed **options and customization options with Pandas**.\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["This concludes our discussion on Pandas and its data analysis tools."]},{"cell_type":"markdown","metadata":{},"source":["So, now we will come to the end of this kernel.\n","\n","I hope you find this kernel useful and enjoyable.\n","\n","Your comments and feedback are most welcome.\n","\n","Thank you\n"]},{"cell_type":"markdown","metadata":{},"source":["[Go to Top](#0)"]}],"metadata":{"kernelspec":{"display_name":"Python 3.10.2 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.2"},"vscode":{"interpreter":{"hash":"8e5977c3052561a792163fb4c7e85a10c6e6c887568c9fcb6af68af793a982d9"}}},"nbformat":4,"nbformat_minor":4}
